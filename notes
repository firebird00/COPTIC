SOR NOTES

Problems with constructing the MPI red/black boundary communicators
___________________________________________________________________

In general, the construction of the multidimensional odd/even
communicator can be thought of as follows:

odd(0)=this element
even(0)=null element
for dimension n=1,nd
	laminate alternating odd(n-1)/even(n-1) into odd(n) face
	laminate alternating even(n-1)/odd(n-1) into even(n) face
endfor

For n>0, the number of non-null elements is the same for odd and even.
But for n=0, the even element is of length 0 which is troublesome.

Therefore it might be better to start at level 1:

odd(1)=odd elements in this dimension
even(1)=even elements in this dimension
for dimension n=2,nd
	laminate alternating odd(n-1)/even(n-1) into odd(n) face
	laminate alternating even(n-1)/odd(n-1) into even(n) face
endfor

This construction must be done nd times, for each one, omitting the 
direction of the face normal nn from the dimension iteration. So really
it is

for dimension n=1,nd
	if(n.ne.nn) then
	laminate alternating odd(n-1)/even(n-1) into odd(n) face
	laminate alternating even(n-1)/odd(n-1) into even(n) face
	endif
endfor

or maybe better:

for dimension nc=nn,nn+nd-2
	n=mod(nc,nd)+1
	laminate alternating odd(n-1)/even(n-1) into odd(n) face
	laminate alternating even(n-1)/odd(n-1) into even(n) face
endfor

Because we are alternating types, we have to use
MPI_TYPE_CREATE_STRUCT, which is the only constructor that allows
different types in the creation.  In that case, we need arrays of
lengths,displacements,types. The length of these arrays is (1/2 times)
the block-side-length, which won't be known. We would either have to
choose a long length or allocate working storage.

Also, it is not clear that there exists a null element in MPI.

If we have to provide working storage, then maybe we ought just to
construct our own indexes and create the communicator directly by
indexing. Then we only have to provide an index array. But it might
have to be substantially bigger.

If we do the lamination directly, what does it consist of?

The even or odd type can be considered to consist of an array of
indexes, referring to the addresses of the values, plus a total length.
A lamination then consists of taking an odd type, taking an even type
shifted by appropriate amount, and concatenating them, then taking
a shifted odd concatenating that, ...

oddnm1=start of odd
evennm1=start of even
odd=start of new odd
do i=1,nsidei/2
   do j=1,nsidej/2
      index(jc)=index(j+odd)
      jc=jc+1
   enddo
   do j=1,nsidej/2
      index(jc)=index(j+even)
      jc=jc+1
   enddo
enddo
ditto for even

-------------------------------------------------------------------
7 Jan 06

Got the block-divided SOR to work, running on MPI processes (on same
machine). Then realized that the gather, to get the individual
solutions back into one big matrix is quite tricky.

One problem is that the order of the blocks generated by the MPI_CART
creation is row major, not column major like fortran, i.e. it goes
in the order 1 (0,0); 2 (0,1); 3 (0,2); 4 (1,0); 5 (1,1); ... etc.
Consequently, when you do a gather, the blocks come back not in the
order you want to store them in in fortran, which would be column
major. That makes it much more difficult to specify the gather, because
a gather puts the data from process-j, in the j-th storage position,
relative to the starting point. It would all be trivial if the blocks
were all the same size, and the order was right. 

It seems that this ought to be fixable by reversing the order of the
suffices. It would be too confusing to do this in the outer fortran
call and specification, I think. But presumably it could be done inside
the block-specification program. The problem can presumably be fixed
by reversing the order of dimensions in the calls to MPI_CARTs.
Yes that seems to work fixing all the MPI_CART calls (create, get, shift).

Now in principle one ought for equal sized blocks to be able to do a
simple gather. There are still major problems with unequal sized blocks.
I suppose that one can construct a generalized call that will interleave
the larger blocks. The iorig pointers to block start are now in the order
of mycartid. This enables iorig-1 to be used for the displacement array.
If all blockstypes were equal we could do
call MPI_[ALL]GATHERV(u,1,blocktype,u,[1],[iorig-1],blocktype,
	icommcart,ierr)
but the problem is that [iorig-1] means an array with values equal
to iorig(j)-1, because of the zero-based C offsets used in the MPI
routines, compared with the 1-based fortran pointers. It would be
possible to change my convention to zero-based. Then a few modifications
elsewhere would be necessary.

Alternatively, one could presumably not bother with all this reordering
of the mycartid, and instead manually reorder the blocks for the
purposes of calls. Do this by creating an array that translates 
mycartid into fortran order. In other words ifortorder(mycartid) =
fortran column major ordered indices, then iorig(ifortorder(j))-1
is the displacement of the jth block. 
	do j=1,nproc
	   idisp(j)=iorig(ifortorder(j))-1
	   irecvcounts(j)=1
	enddo
call MPI_[ALL]GATHERV(u,1,blocktype,u,irecvcounts,idisp,blocktype,
	icommcart,ierr)
Then none of the fiddling around with dimension reversal ought to be 
necessary. There might be a slight memory access hit because the blocks
will come in a strange order. For that reason, the dimension reversal
might still be worth it. 

But wait, it says that the equivalent receive is 
MPI_Recv(recvbuf+disp[i].extent(recvtype),recvtype,i...)
whereas I am taking the displacement to be in units of the underlying
REAL, not the extent of the structure: A problem.

On p207 there seems to be a thing called MPI_UB which is the equivalent
of a null send, but takes up space in the MPI Type. I guess this is 
within a struct. Apparently this is for setting the Upper Bound of a
structure, and there is a type MPI_LB for lower bound. They are not
listed in the type map but affect the value of extent. Apparently
"MPI_TYPE_STRUCT is the only constructor that allows MPI pseudo types
MPI_UB and LB"

-----------------------------------------------------------------------
16 Jan 06
Now have a 2d specific sor2dmpi and a general-dimension sormpi version
going that includes the MPI communications. The general dimension
version is not really fully tested at this stage. Also its Jacobi
radius has a rather different optimum for convergence.

After a day of work we seem to have a multidimensional version of sormpi
working. 

There is a bug somewhere because although different block divisions
of the first two dimensions give identical results, different block
numbers in the third dimension give subtly different results. This 
should not happen.

18 Jan 06
Found the bug, it was in the choice of parity when using the blocks
with the boundary excluded. The parity must be changed by ndims.


_______________________________________________________________________

Turning SORMPI into a solver for embedded boundaries.
_______________________________________________________________________

29 Dec 06

Implemented a test routine comparing solution with smt.out. This is
to discover any errors that I might accidentally introduce. smt.fixed is the
output with which to compare. Comes from the charge-ball case. 

Plan is to introduce boundary handling into this solver code.
For memory access optimization, the plan is to make the pointer to 
the boundary information part of cij, namely the element 2*ndims+1. 
For this I need to fix some addressing in the routines, but not very much.

Added the extra cij slot as cij(2*ndims+1,i,j,...). Works. 
Document minimally. 

Passed the object data obj(idata,jpointer) through to sorelaxgen, which
is where it will be needed for the treatment. Also passed the length
nobj of the obj data (leading dimension). Demonstrated calling it.

30 Dec 06

Now we need a way to implement the objects. I have decided to separate
the object implementation from the rest of the code. That way the instability
of geometric object representation is separated. One can use whatever 
representation one likes provided one has a way to translate it into the
object data that we are going to use. However, we need an object-data
api or specification for how the object data is to be represented. This
needs to be fairly compact, and also not to require lots of processing
during the iterations. There are questions about different numbers of 
dimensions. 

If we make the handling of object data through a function or subroutine
call, we can make the api a matter for the user to specify. However, if
it is too general, then lots of things have to be passed. That would
be cumbersome. It is probably best to make sure that the cij do really 
contain all of the weight from adjacent points that we wish to put into
the numerator. Then the effect of the object code will be to add some
constant quantities. It seems as if this is all it really needs to be able
to do. In fact the main thing appears to be to have the quantity (bdy in
ES2D) to add to numerator, and maybe diag, since this is not now reliably
calculated by adding cijs. For the purposes of potential solving, this may
be all one needs for any given point. 2 quantities. For field interpolation
other information is almost certainly needed.

1 Jan 07

Slow progress. Implemented a cijroutine that is called by mditerate to
set the cij. The cijset.f was an explicit iteration, that I don't really
need since I use mditerate.

Fiddled with getting it to avoid the boundaries properly. Now ok.

Set up series of smt.out to do checking with. smt.1 is the output
from the original, Jan 2006 verified version. smtround.1 is an alternative
output with reduced significant figures. The idea is that if we
get things nearly right, they will match.
i
smt.2 and smtround.2 are the versions that implement the cij in terms
of dxs. They differ by rounding arising from the redefinition. The
difference between smtround.1 .2 are all in the final place. Still 
some differences at the 10^-4 level. Move the test to smt.2 so we don't
have to retain the nint that prevents rounding errors.

Implemented much of the infrastructure for handling the potential
intersections. What remains is to construct potlsect which returns
for any point, dimension, and direction the fraction and potential
value for any intersection between it and its neighbour. It returns
fraction 1 if there's no intersection.

There's a trap with the offsetting of indi that needs to be fixed.

2 Jan 07

Fixed the trap. Rationalized the routines. Wrote a plotting routine
to display the results of the cij setting. There's a problem with that
to some extent that myid is not known prior to the sormpi call, so all
the nodes do plotting, unless you do it after calling. If you do it before,
then all nodes call. One approach is to just call ./sormpitest then. 
That crashes after the plot as it tries to sormpi. Never mind.

Test obj setting seems to work for one point.

Got a sphere apparently working in cij and its plotting, but potential
solution is crazy. Saved its output as smt.b1 for now. 

That problem was that I was not doing the obj treatment in the solver.
Implemented it. Seems to work. 

Switched to pure Poisson (not shielded Poisson) solver. Looks good.
Have to be careful with the external declaration.
Turned off charge density for the test saved as smtsphere.1. Had to turn
off the hand-set object data too. Done.

We seem to have a working solver. Ran a 80x80x36 case in about 10s
on laptop. Took 321 iterations.

3 Jan 07

I realize that there might be good reason to include additional data
into obj. A couple of ideas: 

1. the object number(s) that the intersections correspond to. This
would be useful for calculating the total flux out of a given
object. However, it would have to be specified for each of the
directions. So that would be a very cumbersome number of additional
elements, almost doubling the storage, if done directly. Needs thought.

2. the address of the cij (or ijk pointer) of the mesh node that this
object belongs to. This would enable one to scan the obj data, and refer
back to the mesh, rather than having to scan the mesh and refer to the 
obj data. 

To store the latter in a real is somewhat problematic, since the mesh 
might become larger than the integer available. Probably one way to 
solve that is to use an equivalence of obj to an integer.

Another issue is the namespace that obj is in needs to be observed now
that it is in common. Start by fixing that. Done

Separated the specific objects into 3dobjects.f
Took out the save from circleset and created smtsphere.2 to match.

Object information: probably the best way to handle this is NOT to put
the additional information we might want to retain into the sor_obj
data. Instead we can optionally create and populate additional object
data structures that parallel the sor_obj and give the information.
This would be implemented in routine potlsect, where the intersections
and fractions are calculated. There's a slight problem in that isor_oi
is incremented only after potlsect has returned, so syncronizing the 
additional data with isor_oi is a little tricky. One way to syncronize
would be to pass iset to potsect, telling it thereby whether we have
already incremented the isor_oi or not. Then one just writes the additional
data into isor_oi-1+iset. If we are storing the pointer to cij, we
may also have to pass that to potsect. The parallel information could
be integer.

11 Jan 07
Implementing general boundary conditions. 
Converted the fixed boundary to general form. Some thoughts about
how to pass the a,b,c. 

Also need to pass back more information for the continuity condition.
Do that by changing from passing in dpm the fractional distance. Instead
pass the total distance, so that dp = dpm(i)*fraction(i) etc.
Unfortunately this changes the rounding. So store this result as
smtsphere.3

The general condition does not seem to be working correctly. There's a 
problem with the inactive side, it seems. Need better diagnostics.
Implemented surfmark. This seems to show that the mismatch is really 
occurring at the surface, not on adjacent points. It also shows the directions
of the connections are not what one might intuit from the surface plot.
So you have to be careful.

13 Jan 07

Finally found my problem. It was that I was storing Cd in the object instead
of the DIFFERENCE Cd-Cij, which is what I should have been storing. 

Adjusted the namespace control by changing to a suffix rather than a prefix
_sor. This enables variables to determine their type in the usual way.
objcom.f fixed. ctl_sor also fixed.

Change to using a proper 0-1 range for the variables. Replace smt.out
to smtsphere.4 smtround.3.

Doing numerical checks, I find that the logarithmic derivative setting
is not giving correct solutions. I find that adjusting the coefficients
inside cijroutine can correct. It seems that the problem is with my
implementation of the form for the general BC. I make d+ equal to 
apb+b/apb times dxp1, but then for the opposite direction, I have not used
d- equal to this same value. I have used just dxp1. That is incorrect.

Rebuilt the cij routine using the proper values for dminus (and the full
continuity expression). Gives correct answers 40x40x16 has maximum
error for the 1/r case of .0032 and SD .001. 
For 40x40x40
 Max error=  0.00121030153  Standard Deviation=  0.000311983633
This seems to be second order small.
For 80x80x80 the oi_sor overflowed. Doubling it solves. then
 Max error= -0.000307714043  Standard Deviation=  9.30291717E-05
Reduced by faster than dx. Not quite factor of 4 in SD, but yes in max.
Looks as if we are getting second order accuracy.
For 20x20x20
 Max error= -0.00420894753  Standard Deviation=  0.00136070442
Definitely looks like dx^2.
For 10x10x10
 Max error= -0.0172496308  Standard Deviation=  0.00511154439
For 100x100x100
 Max error= -0.000233839804  Standard Deviation=  7.77521054E-05
This is getting closer to the eps convergence:
 mi_sor,k_sor,xjac_sor,del_sor 1210 401  0.999440014  1.9293886E-05 0
Wrote plotconv to plot the convergence of these cases. Very clearly
quadratic except for the 100 case where we seem to be getting less than
quadratic reduction, which is not surprising since we are not necessarily
converging the iterations to significantly better accuracy.

Running quantitative test case again finds rounding differences, but
zero rounded differences. So consolidate in smtsphere.5, smtround.5

Summary: We have the scheme working and tested with both fixed potential
and logarithmic gradient boundary conditions. 

To do: media. Rethinking stored data (for charge assignment, object
identification, reverse reference to cij, etc).

Longer term ideas: curvilinear coordinates.

What to store in the object data? Prior idea was fraction, potential. 
This works for a fixed potential boundary and gives enough information
to generate an interpolated position. With other types of boundary it
is not so clear what one should store. 

18 Jan 07

Begun adjustment of the object data. First generalize the code so
that ndata_sor is a parameter that describes the amount of data per
direction. Ensure that it works for ndata_sor=3, even if we are only
using the prior two spaces. Of course, at present the data is only 
being used by the plotting routines for a graphic display.

Then I can add 1 to the start of each of the object data descriptor
pointers:
      parameter (ndims_sor=3,ndata_sor=3)
      parameter (nobj_sor=1+2*ndims_sor*ndata_sor+3)
      parameter (idgs_sor=1+2*ndims_sor*ndata_sor+1)
      parameter (ibdy_sor=1+2*ndims_sor*ndata_sor+2)
      parameter (iflag_sor=1+2*ndims_sor*ndata_sor+3)

Need to correct things all the way through sormpi.f. Probably it is better
to remove the process of passing the object data through and rely on 
external calls. So implement ddn_sor(ip,dden,dnum) that adjusts the numerator
and denominator. Unfortunately this gives rounding error changes.
Make smt.6

Remove the passing of nobj, and obj from the sormpi and sorrelaxgen calls.
This is now entirely in the common and its effects within the sormpi call
are purely the dden and dnum adjustment via ddn_sor(ip,dden,dnum). There is
negligible hit on the speed.

27 Jan 07

Planning and development of box handling for incorporation of surface
descriptions through box analysis.

boxedge iterates over the edges of a box in levels going out from the
	base node 000... 

gaussij is a modification of the numerical recipes gauss-jordan elimination
	to make it robust to singular matrices. 

Before incorporating these into the sor, it is probably best to implement
the c/a, b/a aspects of the code. Did that.

Now got a call to boxedge going after the cijs have been set. It seems
to be giving sensible results. For example the replacement of intersections
shows that when replacement of a real intersection takes place (more often
than is nice) it is because of rounding in late digits. 

Developed wireframe plotting diagnostics in cijplot to tell if I am
doing the right thing. Plotted the true intersections. They look fine,
although there are box recuts that I don't understand being
tried. Perhaps that is a sign that I need a better points-chosing
scheme.  This does not validate the rest of the fractions,
though. Need some inspiration on how to verify the other fractions in
a graphic way.

31 Jan 07

Changed additional fraction calculations to use all the points on levels 
up to that being examined, and svdsol to fit a plane to them. This gives
results the same within rounding as the gaussij when the number of points
is 3, and similar results otherwise. 

There is still an issue about recutting the cell. 
I still do not seem to have a clear verification that I have got the
additional fractions correct. 

An idea. The plane equation is \sum fn_i^-1 x_i = \sum a_i x_i= 1. 

For a sphere this ought to be a tangential plane (approximately). We
could test whether it is by evaluating the distance of the sphere
center from the plane, which is (\sum a_i.xc_i -1)/|a|, and seeing if
this is equal to the sphere radius.
 
Note that any box that has one of its fractions unset (=1.) should be
considered to have no plane crossing it. Thus each unset fraction 
rules out all boxes in that direction. If a node has three unset fractions
then there is only one of its boxes that is cut. There are some of these
among the Added. But there are others that have more than 3 fractions set.

3 Feb 07

There seem to be persistent erroneous boxes among the vast majority of 
correct boxes. I am pursuing the idea that these arise because of the
overloading of the fraction settings. If all three of the fractions
for a particular box happen to get set by the adjacent boxes, then this
box will erroneously be intepreted as having a plane intersecting it.

The only way out of this that I see is to use the flags to indicate whether
a box is in fact cut by a plane or not. There are 2**dims possible boxes.
Thus if we use all of the 32 bits of a 4-byte word, we can cope with 
2**5, i.e. 5-dimensions. 3-D requires only 8 bits. The intrinsic 
btest(n,ipos) yields true if bit pos of integer n is set. This extension
is in the mil-spec and available on practically all compilers. There is 
also an intrinsic ibset(n,ipos) and ibclr(n,ipos) (I think I got those right)
Their availability is less certain. They are not mentioned in current
gfortran documentation. 

After substantial additional work, I found that the main problem was that
the handling was in the wrong place in boxedge and hence incorrect.
Moving it to the proper end of level gives good results. 
If we use the test that we don't account for planes that fail to intersect
the cell, we get only about 40 additional pointers for the correct planes.
We get no recuts. We get no errors above .01. Also we find that only 
6-intersection cases are found. This is the effect of the cut criterion.
If we remove the cut criterion, we get many more additional points which
have 3,4, or 5 intersections.

I think we have the thing working now. Flags signal whether a box is
relevant or not. They are set only according to the boxedge call.

The next thing to do is to implement the field (gradient) interpolation.

6 Feb 07

Further cases with different radii shows there are still some problems
to sort out. I had a test that replaced the fraction only if b/a,c/a
are zero. If you have a zero potential setting. That is the case even
for previously found fractions. Then problems arise. Therefore, I ought
to reset the fraction in the box code only if it has not been already
set, i.e. not adjust it smaller in succeeding calls, as had been the 
previous algorithm. I think that algorithm was supposed to handle
cases where it had been set by previous box calls (not direct fractions). 
Now choose only to permit fraction setting if fraction =1., i.e. it has
not previously been set at all.


2 Jun 07
Converted the object code to depend on reading an input file in which
different types of object can be specified. Also coded the ability
to detect whether we are inside (or outside) such objects.

9 June 07
Got the gradient interpolation working with correction of the node about
which interpolation is done to use the fraction information to determine
when we need to use something other than the nearest node. 
Packaged this into gradinterpcorrect. So the call is packaged.

15 Jun 07

Added ipointer to the idob_sor data: a reverse pointer back to the
u/c arrays. Created routine:  indexexpand(ndims,ifull,index,ix)
to obtain the multi-D index ix, from the pointer index.
Then added routine iregioninit(ndims,ifull) to initialize the 
iregion flags for the idob_sor to the insideall value telling what
region they are in. It cycles over all the object data that is
created by the cijroutine, uses indexexpand.

Thus we now have ipoint_sor and iregion_sor set to sensible values
after calling cijroutine and iregioninit. Then at any interpolation,
we can access the region of any point that has object-boundary data.
A point that does not have such data is not adjacent to any boundary.
Therefore, it is safe to assume that it is in the same region as
a nearby point that we might wish to compare with. 

20 Jun 07
Attempting to compare the gradinterpregion call with the other, we find
that the iregion values are apparently incorrect. Misaligned by 1 in
all dimensions. This appears to be because when the cijroutine is called,
it is called by mditerate, and this is relative to the origin
(2,2,2) in the 3-d cij array. Consequently the reverse pointer is 
set incorrectly. Or, to put it another way, the reverse pointer is
relative to the (2,2,2) origin. Fix this in the reverse lookup during
the regioninit. Now gradinterpregion gives identical results.

22 Jun 07
Got getfield working. It gives the same value as the raw calls. Also
seems to give plausible looking interpolations.

23 Jun07
Constructed fieldtest which plots a field profile along a radius of the
sphere and a chosen angle. It shows there's a bug in getfield. 
Made get3simple to do totally simple box interpolation with no 
gradient extrapolation and neglect of boundaries. 
Found the bug in getfield logic. Incorrectly handling the construction
of the inputs to boxinterp for general dimensions. Temporarily use
the 3-D version from get3simple for iteration. That works and now things
agree away from the boundaries.

16 July 07

Getting back to this. The fieldtest code is close to working, but it
currently does not do interpolation correctly, because it produces
cases where iflags(1)=0, contradicting the assumptions of the
box2interp version. 

Extended box2interp to cope with f00 absent. Then tests show that the 
errors are reduced by a factor of 2 in the prior worst cases. So this
really helps (getting the interpolation right). 

18 July 07

Implemented an extrapolation scheme that is used for a box in which
more than two nodes are absent. If an absent node has precisely one
(of two) neighbors present then extrapolate through the present node
using the value one step further away to the desired (absent) node.
Otherwise do nothing because if only one node is absent (i.e. a node
has two present neighbors) we are already doing the sensible extrapolation.

This code has the effect of reducing errors in E-field by about a
factor of 2 when it kicks in. But there are fairly significant errors
in which it does not. Generally we find now that the field error is
less than about 10% for the 16x16x20 mesh near the sphere
boundary. Since the boundary is at r=0.2, which defines the
scale-length of the phi-solution there, and the node spacing is 1/16 or 1/20.
which is 0.05 (optimistically), the ratio of node spacing to characteristic 
scale-length is 0.25. Therefore if we get 10% errors we aren't doing
badly. Going to twice the mesh numbers (half the spacing) the errors drop to 
about 2-3% max. Which seems to be falling like (s/l)^2 (or at least faster
than linearly). There was a strange result with 
 fieldtest -p -p1 -t2.4
some kind of error inside the sphere but not too bad.

Looks like the difference between using extrapolation or not is still only
about a factor of 2 at smaller s. The extrapolation does not change the 
order of interpolation (as expected). That order is presumably that we
are correct to first order, since we are doing linear E-interpolation.
The error being order (s/l)^2 thus makes sense.


23 Aug 07

Started padvnc.f for advancing.
Updated getfield to use general number of dimensions.
Removed extrapolation from it, but saved old version.
Removed passing of iLsc, just multiply iLs by (2*ndims+1).


24 Aug 07

Further cleaning and confirmation that padvnc is working.
Changed getfield so that it is permissible to pass the full mesh
position, not just the fractional mesh position. This gives a version
that can either be used by passing the local origin of arrays, or
be used with the global origin and full mesh position.

There is a puzzle about the following. It seem to be using incorrect 
offset (ought to be (ix-1)*iLs ) but it works as is.

      do id=1,ndims_mesh
c Offset to start of dimension-id-position array.
         ioff=ixnp(id)
c xn is the position array for each dimension arranged linearly.
c Find the index of xprime in the array xn:
         ix=interp(xn(ioff+1),ixnp(id+1)-ioff,x_part(id,i),xm)
         xfrac(id)=xm-ix
         x_part(ndimsx2+id,i)=xm
         ixp(id)=ix
         iu=iu+ix*iLs(id)
      enddo

Interp returns a value >=1. But if we have ix=1, that is the first 
value in the array, so the offset should be zero and iu zero.
In the interpolate.f file (ix-1) is used, correctly.
In padvnc.f it is not. The getfield calculation in fieldtest appears
to treat things correctly, because it uses u(ix,ix,ix) explicitly.

I think this is bound up with the fact that I've assumed that we can
treat the shifted/fractional and full position cases the same, but
perhaps we can't since the fractional treatment passes 0.5 but the
full position value at 0.5 is 1.5 reading from a lowest index of 1.

Actually I think the previous result was wrong and the present one is
right. Played around with the padvnc printing out the force and comparing
with analytic. The corrected results are within about 2%, but the orbit
closure stinks.

Yes this is the correct alignment. The orbit closure improves lots
as one goes to finer mesh. This agrees quite well with analytic approx.
Fixed some little problems. I think we can declare padvnc working 
using (ix-1) everywhere.

25 Aug 07

Completed the initial chargetomesh assignment code.

Thinking about how to handle changes to the boundary potential between
steps, which would be needed for floating cases. Introduced a new
iinter flag in dob_sor to indicate which object was intersected. (Not 
yet populated.)

There seem to be three levels of cij update that would make sense, in
increasing level of computational cost.

1. Directly scale the C/A and ibdy components by the changed potential
for a specific object whose potential is varying. Assumes that objects
are not moving and that the changing BC is fixed potential. And that
each node that intersects the changing object intersects no others.
Involves searching the existing dob_sor data.

2. Rerun cijroutine for those nodes which intersect a changed object.
Assumes objects not moving, but would work for arbitrary changes to 
BC(s). Just operate on the existing dob_sor data.

3. Do 2, but in addition, search nodes in the neighborhood of a moving
object to determine nodes that become boundary which weren't before
(and presumably those that stop being boundary but were before). 
This requires substantially more effort to be sure you don't miss new
nodes. But is still short of re-searching the entire mesh, which would
be very costly.

A further possibility would be to limit the intersection investigation to
only the object(s) that have changed. This might be a significant time
saving. In other words, ignore the other objects in calculating intersections.

Implemented writing of the object number into iinter_sor. Test is
that we use cijplot to plot wireframe with color equal to the number.
Works.

27 Aug 07

Looking into MPI id's and communication, with a view being able 
conveniently to call the setup before starting the sormpi solution.
This enables me to know what my process is etc.
There are currently two separate initializations. 

1. bbdydefine just sets the iorig vector which tells the block sizes
for the specified arrays and process arrangement

2. first call to bbdy sets up the communications and initializes MPI.

It hardly seems necessary to have these separate calls.
There's an issue about how iorig is saved. Currently it is only
saved during the operation of sormpi (lost on return). 
Certainly there's no need to do what is currently done which is
to call bbdydefine anew each time sormpi is called. It really ought
only to be needed the first time.

There is a general save in bbdy which is where most things are saved
(although apparently not iorig because it's an argument). I see no
real reason why iorig should not be saved. Indeed there does not seem
to be any reason why it normally should be accessed outside of 
bbdy, so it might simply be defined in a common (in case access is needed)
within bbdy, and not passed to it. Then bbdydefine would be called by
bbdy itself, not separately. If we keep the arguments to bbdy the same,
then iorig has to be saved in sormpi. That's a problem because if we
call bbdy outside of sormpi, and then think we've done setup, it won't
then be given to sormpi for subsequent storage, unless we reinitialize,
which would be a bad thing.

Better to delete iorig from the bbdy arguments. Places:
mpibbdy.f mpibbdytest.f sormpi.f bbdydecl.f
However, we also then need to add ifull to the bbdy arguments
otherwise the initialization doesn't know what they are.

Done all that. mpibbdytest works (2 processes). fieldtest works.
Fieldtest had no modifications to it to handle this change. 
The whole interface is unchanged in respect of anything outside sormpi.

Added the code for special case kc=-2 purely (re)initialization.
A prior call with kc=-2 will set up the communicator but not try
to actually do any communication.

This all works, but there's still a problem with calling the bbdy
directly, that is that all its (other) arguments don't end up in the
sormpi places, which is where they are needed. Probably the best
thing is to make the bbdy call through sormpi somehow. The integer
switch ictl is the right place to do this. 

Implemented that using the 3rd bit of ictl.

Found a big problem with the initial call causing sorrelaxgen errors
and segfaults. Traced one issue to new usage of iLs which is not 
correct now because in bbdy bbdydecl of integer iLs(ndims+1) has ndims
as a parameter but iLs not passed. That's ok in bbdytest, but not in
sormpi. The error is not detected by the compiler and then shows
up later only when the save is required. In general there's an issue
with using bbdydecl in sormpi because a number of the bbdydecl parameters
are not passed in to sormpi. Therefore they are really local definitions
and can't be sized by anything other than a parameter. 

Fixed that for now with a hack to make it a parameter. Annoying compiler
bug!

28 Aug 07

Initialization of 32x32x40 now takes about 4 seconds.  When thinking
about the initialization, and possible reinitialization if there are
boundary changes, it is clear that for a multiprocessing environment,
we ought to make each processor do its own cij initialization.  This
potentially makes a big time saving.

However, the way things are currently set up, the cartesian layout
is hidden from the main routine, but the main routine calls mditerate
of cijroutine. Thus the information is not available to divide the 
work between different processors.

There's another issue which is that cijroutine uses an indexed array
of object data. As it generates the array, the presumption is that
there is a 1-1 correspondence. If the cijroutine work were divided
between processors, then the would be a 1-many correspondence. The
object data corresponding to a particular pointer would refer to
different mesh- locations in different processors. That would have a
possible benefit in that the object data storage would be
distributed. But it would cause a problem in that we could not simply
gather the data together.  That is a MAJOR problem because the
interpolation routines currently assume that there's a cij with
corresponding pointers covering the whole of the volume. It would
perhaps be possible to segment the object data by offsetting the
pointer for each processor so as to keep the data separate. Then we
could gather the cij back to central location.  Unless we did this, I
shudder to think how we'd proceed. The cost is the segmentation of the 
object data storage, which might make it less efficient. The benefit
is presumably speed of recalculating cij.

Basically we need access to the iorig information in order to do much
with other processors, such as mditerate or iregioninit. Actually that
can be accessed through iorigcom. We might also need information about
our place in the cartesian communicator; this would be in the form of
iobindex or myorig. 

Looking into the partreduce and other mpi code. There's some awkward 
shuffling in sceptic. This is not necessary because using the argument
MPI_IN_PLACE instead of the send buffer causes in-place reduction, 
which avoids all the problems of shuffling. Much more elegant.

Implemented a basic mditerarg of psumtoq to calculate the charge
density. But we still need a way to calculate rhoinfinity which is passed.

Put a new solve of sormpi in the stepping loop. It shows a blip of
charge giving rise to a potential peak. (And also causes the particle
to veer off in a different direction. Probably that is some sort of
image-charge effect). 

On a single processor, a 32x32x40 solve of about 100 iterations takes ~1sec.
Not bad, although the resolution is not that great yet.

Working on horace. Found several compatibility problems. (gfortran)
1. Makefile does not use implied patterns correctly. Seems to be something
   I don't understand about the match-anything rule.
2. I made incorrect assumption about o implying integer. Gfortran detects
   that error and one with pwr2nd, because of checking for real arguments.
   Fixed.

Succeeded in making. Got some complaints about blanket saves. Seems to be
caused by saves in mpif.h.
Also got diagnostics about unused argument variables.

29 Aug 07

Corrected the sign of field to make attraction of the particle to image
charges correct. Things seem fine with last night's changes.
Code will compile and run on unity. There it is back to g77 not gfortran,
I think.

Reinjection. We need to have some sort of approach on this. There needs
to be some reinjection boundary identified, and some way to determine
where on that boundary and with what velocity the particles are going
to be reinjected. 
A spherical boundary is basically the sceptic situation.
A rectangular boundary might also be of interest.
Probably these should simply be provided as subroutines.

Incorporated a somewhat modified version of the old reinject.f routine
from sceptic. Sphere. Seems to work but not quantitatively
verified. The advancing by a partial step is to be incorporated into
the padvnc code. 

Next thing: Loading particles. I'm not wonderfully happy with sceptic
on this. But I don't know if there's a better way. 

30 Aug 07
Implemented pinit. But there's some kind of bug that causes it to hang
in some situations. That was incorrect iregion_part value.

31 Aug 07
Idea about different particle species. We could use if_part to identify
different species 0: no particle 1: species 1, ... They padvnc could be
adjusted to advance each species differently, and reinjection could likewise
reinject different species. This would make it essentially trivial to
generalize the code to make it PIC electrons (for example) or multiple
ion species.

Branched to ccpic as main. Then began packaging the diagnostics so
that we can clean up the code, and use consistent mesh sizes etc.
I realize we need to worry about the wrong field we are getting at the
edge. This is an error that needs to be understood and fixed.

1 Sep 07
Trying to fix the edge incorrect field. First, try to set the iregion
flags in all the edge object data. This sort of works, but I find that
there's a problem with the fact that the reverse pointer is in various
places assumed to be addressed relative to (1,2,2,2). This was because
of the problems with mditerate. 

Therefore change the way that mditerate is called with cijroutine.
This needs us to fix the passing of the ipin to mditerate to do the 
right thing, and to calculate the right indi and save the indinp
in mditerate.

Then there are two places where the 2,2,2 assumption must be removed.
One is in 3dobjects.f iregioninit, called by objstart.
The other is in cijroutine itself. Both fixed.

Now the edge iregion is initialized with iregion as well as the
intersections.  This improves the field diagnostic plot a great deal,
leaving only a tiny region actually outside the outer object where the
field is incorrect. I still don't quite understand why that's there.
I guess there's no reason it shouldn't be, since the presumption is that
getfield returns only the field corresponding to the iregion specified.
Actually, no, I understand this, inside solu3plot the iregion is set
to be the insideall of the actual position being plotted (and without
that one gets rubbish). So we are telling getfield that we want the 
value as if one were in the region in question. Improved solu3plot
to show the region.

Trying out non-uniform mesh. There are big problems. The autocolorcont
is now incorrect. But more important, the getfield is plainly incorrect
and it looks as if there might be a bug in getting the spacing. At least
the solution looks plausible!

3 Sep 07

Fixed the contouring.
Fixed getfield. It was indexing the position array slightly wrong.
Now things seem to be correct. However, I think a numerically 
analytic orbit ought to be examined to prove that we are getting the
correct orbit.

4 Sep 07

Did an installation of an exact circular orbit. Seems to give rather
good accuracy after 100 steps with dt from .1 to 1. (0.7 to 7
turns). In the vicinity of 1-2 % accuracy in the r over that
evolution. About 5% deviations with 400 steps (28 revolutions), but
still only 1-2% for 400 steps 3 revolutions (dt=.1). Thus there's some
effective collisionality but it is not terribly great. Allows many tens
of revolutions. This all with 32x32x40 mesh r=1-5.

Tried 100,000 particles with dt=1. Goes at about 2 iterations per second.
200,000 goes at about 1s per step. No significant difference with dt=.1
This is without -ffortran-bounds-check.

Using profiling and gprof we get

 22.81      3.17     3.17 23890368     0.00     0.00  gradinterp_
 15.11      5.27     2.10 24594336     0.00     0.00  gradlocalregion_
 14.75      7.32     2.05  6148584     0.00     0.00  getfield_
 10.54      8.79     1.47  6763776     0.00     0.00  circlesect_
  6.73      9.72     0.94  6148584     0.00     0.00  interp_

Most of the time is being spent getting the field and in its interpolation.
If we put a short-cut into gradlocalregion to do the calculation directly
if the icp0 is zero (not a boundary), then we get:
 time   seconds   seconds    calls   s/call   s/call  name    
 31.21      4.38     4.38 24594336     0.00     0.00  gradlocalregion_
 16.33      6.67     2.29  6148584     0.00     0.00  getfield_
 12.02      8.35     1.69  6763776     0.00     0.00  circlesect_
  7.49      9.40     1.05  8993020     0.00     0.00  inside_geom__
  6.78     10.35     0.95  6148584     0.00     0.00  interp_
  6.06     11.20     0.85      314     0.00     0.00  sorrelaxgen_
  4.49     11.83     0.63  3739985     0.00     0.00  gradinterp_

There's not much savings of time. The shortcut has added about 16%
(2.3s) to gradlocalregion, which came out of gradinterp. There's no
substantial total savings (<3%). This shows that it is really the
calculations that are costing us:

         uprime= (2.*x+dx0)/(dx0+dx1) * (up-u0)/dx1
     $        +(dx1-2.*x)/(dx0+dx1) * (u0-um)/dx0

If we reorganize that expression to
         uprime= ((2.*x+dx0) * (up-u0)/dx1
     $        +(dx1-2.*x) * (u0-um)/dx0)/(dx0+dx1)
We get
 time   seconds   seconds    calls   s/call   s/call  name    
 30.70      3.91     3.91 24594336     0.00     0.00  gradlocalregion_
 16.20      5.97     2.06  6148584     0.00     0.00  getfield_
  9.79      7.21     1.25  6763776     0.00     0.00  circlesect_
  8.22      8.26     1.05  8993020     0.00     0.00  inside_geom__
  7.47      9.21     0.95  6148584     0.00     0.00  interp_
  6.29     10.01     0.80      314     0.00     0.00  sorrelaxgen_
  3.85     10.50     0.49  3739985     0.00     0.00  gradinterp_
A small saving.
Similarly, we get a small saving from using icp0=cij(1) instead of cij(ix).
Reorganizing test gets time to 3.74s. Another small saving. But we have
not done much. Probably only a 10% saving.

The profiling conclusion is that the main cost is the parabolic
interpolation of the field-gradient, which is called four times for
each dimension for each particle at each step. By fiddling around 
inside that (gradlocalregion) implementing two conditional short-cuts,
I shaved about 30% off the routine for uniform scaling. Everything else
seems pretty marginal, and is not worth effort at this time.

time   seconds   seconds    calls   s/call   s/call  name    
 23.07      2.85     2.85 24594336     0.00     0.00  gradlocalregion_
 17.28      4.98     2.13  6148584     0.00     0.00  getfield_
 10.83      6.31     1.34  6763776     0.00     0.00  circlesect_
  7.38      7.22     0.91      314     0.00     0.00  sorrelaxgen_
  7.22      8.11     0.89  6148584     0.00     0.00  interp_
  7.18      9.00     0.89  8993020     0.00     0.00  inside_geom__
  6.12      9.75     0.76  3739985     0.00     0.00  gradinterp_

5 Sep 07

Reorganized some files to clean up the main program and put plotting
and some other stuff elsewhere. 

Checked the cvs that you really can build from it. 

Now we need to get the volumes correct for calculating the charge
density.  This is trivial for the core nodes. Only difficulty is for
those on object boundaries. In cijroutine and boxedge we do some
elaborate calculation of fractions, which are supposed to represent
the points that define a plane approximation to the bounding surface
cutting a particular box, in the case that the plane actually cuts the
cell surrounding the box (which it can do even if fractions are >1).
However for the CIC particle assignment, a particle contributes
partially to a node if it is in the _box_ (not just in the node-cell,
which extends to the half-node-spacing position). Therefore, it is not
clear that I have done the relevant calculation. There will be some
degree of volume reduction for every node that lies in the center of a
2x2x2 box which is intersected by the boundary.

Things would be different for NGP assignment. Then particles contribute
only if they are in the node-cell, in which case the fractions might have
some value. 

In either case, there is a problem in that currently particles are 
removed based on the iregion. That is not a planar approximation. 
If volumes are calculated on a different basis from the particle removal,
the charge-density calculation will not be done correctly. It would
therefore be inconsistent to use direct iregion evaluations for particles
but fraction-approximations for volumes.

One alternative approach would be a Monte-Carlo integration of the
volume by multiple calls to insideall. If the weighting were uniform
(which it is not) then this amounts to a random choice of region in or
out. So n points are distributed according to a binomial. The average
of a sample therefore has a mean number: np (where p is the
probability of acceptance) and variance np(1-p), so that S.D./mean =
sqrt((1-p)/np), and the uncertainty as a fraction of the total box
volume is sqrt(p(1-p)/n)<=sqrt(1/n)/2.  Consequently, to get 1%
accuracy requires n=50^2=2500. Rather a lot of random points (3 ran0
calls per point). If we used a uniform mesh in each direction, with
this total number of points, we would have 2500^1/3= 14 per direction.
That would give a worse result in terms of uncertainty (probably). 
Monte-Carlo is better in dimensions greater than 2.


11 Sep 07

Started volintegrate and volnode for node volume calculations.
Transitioned active code to using mditerarg instead of mditerate.
However, haven't pruned all mditerate because the calls of mditerarg
are a bit hokey, since they use inconsistent number of arguments.
This should not matter, since the arguments are at the end. However
it probably violates fortran standards. So probably ought to think
about making the calls consistent.

Calls to volintegrate amount to 2152, according to gprof, which is a
major hit on initiation: about 8 seconds. This is for the 16x16x20
mesh and 10000 points for the montecarlo integration. Total pointers
used is 2800, but that includes the edge. As mesh size increases
the boundary points scales like n^2. So a 100x100 mesh would 
probably be about 6^2=36 times longer. One approach might be to 
do this work shared between the nodes. That would reduce it back to
about 8 seconds. Of the used time, about half is calls to inside_geom
which is the routine that is called for each object to determine if
the point is inside it. 

It might well be worth saving the volume data in a file, to be read
back in, in most cases. Done. File storedgeom.dat and seems to work.
There are numerous cross-checks to try to make sure this is valid
data for the case being run. 

12 Sep 07

Implemented a text plot of volume percentage. Seems to show things are
working ok (except for the external volumes). 

Increased the npoints parameter for monte-carlo to 10^5. This reduces the
random errors to <1% as expected. 

Made the volume for nodes external to active region 100%. But perhaps
the more appropriate thing would be to use their region for their
volume, or possibly a very large number so that the charge density
becomes negligible.

Discovered that if the network is in a certain type of unconnected state
then program takes for ever to initialize. This appears to be an MPI
problem.

How accurate does the volume have to be?

Well, the accuracy of the charge density is the real question. But
that has statistical fluctuations at a fractional level of 1/sqrt(N),
where N is the number of particles per cell. Thus, from a purely
statistical viewpoint, all we really need is to calculate the volume
from a monte-carlo sample of points much larger than the number of
particles in the cell. If we have a million cells (the upper range of
what might currently be managable) then 7 million particles would give
only 7 per cell.  That would make the use of 10000 points per cell
overkill.  By contrast, a 20x20x20 mesh has 8000 cells, and so we
would have a maximum of about 1000 particles per cell for this very
small mesh. Therefore, 10000 points is certainly enough to make the
statistical noise from volume calculation less than that from
particles.

There's something of a compensating factor: the particle number might
be averaged over many different realizations, while the volume remains
fixed and does not improve with averaging. Consequently, one might 
find that such quantities as the flux distribution, when averaged over
many steps, might show significant effects from cell volume errors.

14 Sep 07

Implemented a rhoinfcalc based on smax flux. Run with 1000000 particles
and zero sphere potential, it gives about 4000 reinjections per step
when it should give about 2400 or so. Thus the density inside is 
considerably less than rhoinf. Played around with this. Eventually found
that the problem is we don't have electrons turned on and so this gives
a strongly positive potential even with zero on the sphere.

We need to introduce debyelen and set it to some sensible value.
The solution of L\phi = q means that we either have to put the debyelen
scaling into the difference stencil or into q. That is we either have
to consider the equation to be \lambda^2 L\phi =\rho, 
or L\phi = \rho/\lambda^2.
The latter means that the "density" is stored as density/lambda^2.
The former means that the cij coefficients are scaled by \lambda^2.
From a computational viewpoint either is probably fine.
Actually I notice that the sceptic solver adjusts the overrelaxation
according as lambda is large or small. Probably this is not necessary
for ccpic, but might speed up things. In sceptic, I multiplied the 
poisson coefficients by debyelen^2. Perhaps that's what I should do here.
It's slightly awkward because dpm is passed up from the geometry routines.
I don't think the debyelen should be put into them. 

So put it into cijroutine. Then we can get small potential by making
the debyelen very long (with zero potential on sphere). Then we get
correct numbers of reinjections and sensible rho approximately one.
The sor convergence is a bit slower like this. We are committed to 
using mditerarg by this choice. Found that there's a problem, namely
that when setting derivative, there also needs to be a debylen 
factor in this approach. Seems to be fixed by scaling b as well.

Now we have a segfault from the -gt case. OK fixed that it was the 
adjustment I had made to slice3plot. But we still don't have the 
interpolation correct now. Ok one needed to fix another place in
cijroutine.

Need now to turn on the electrons. Doing this things are very broken
for few particles, but seem to work for many. Also there's a problem
outside the active region, where faddu is being added, though it 
shouldn't be. It might be possible to put the q equal to 1 in the 
outside region. That would cancel out the electron function.
But it looks like being a major bother.

18 Sep 07
Actually it is not a problem because volumes is set to a very large 
number outside the active region. This is easily used in psumtoq to
set q=1. Seems to work.

20 Sep 07

Now we'd like to get the code going with constant number of particles being
injected per unit time. This might be a more satisfactory solution than
calculating rhoinfinity each step based on the number that happens to be
reinjected. 

Done that. The total number of particles shows a decay over about 100 steps
of .1, by about 10%. This is presumably the readjustment of the initially
uniform density to reflect the proper final spatial distribution. 
Now we have the choice of specifying -ni the number of ions or specifying
-ri the rhoinfinity (density of ions at infinity). May not have the 
multiprocess numbers set correctly yet.

I wonder if there's a way to speed up the convergence to the final density
other than what we've always used in sceptic, which is large initial steps.
Once we vary the dt, we will need to vary the ninjcomp accordingly. 

Observed that there's an error in u inside the sphere. This arises because
the electron density is not being correctly compensated there. Changing
the setting of rho to be faddu(u) for an external region helps, but does
not fix this. The error mostly goes away if rho is set to zero. This is
a serious puzzle. Seems as if the solver is incorrect in the inner
sphere. It is possible there's an error in the algorithm for the case
when faddu is present. 

It's really bizarre, but putting the rho equal to minus faddu in the
inner region gives a perfectly flat profile. But in the outer region
you need +faddu. Explain that! Actually it seems to be an accident.
It does not work for other sphere potentials.

Found a bug in the faddu part of sorrelaxgen.f. Fixed it. But it's a
bit worrying for sceptic. It's ok. Sceptic uses a hard-wired 2-D sor,
not the sorrelaxgen. I think we now have a correct compensation for
electron density in the external regions.

Fixed some sliceplot bugs in rotation.

21 Sep 07

Things to do next maybe.

Reading and Writing the code state, fields and particles. Probably we
should keep the fields and particles in separate files since the fields
only need to be written by master, while each node must write its own
particles. How do we ensure that random numbers are the same thereafter
for a restart?

Tracking and saving particle exits (and entrances?). This depends to
some extent on the type of object. So we need a uniform way of
handling the documentation of flux distributions. This requires an api
for the object.

MPI communication of particle parameters. 

22 Sep 07

One thing slowing down my decisions is the problem of the overwhelming
amount of data. Even to save the fluxes at each step is going to take
a substantial amount if we do it for every object of 32. Of course we
will rarely or never want to do it for so many objects. Probably we
should not use a structured obj_flux(n_fluxmax,ngeomobjmax) data store
for the object storage, because this is going to be very inefficient.
Instead we should probably use a big storage space accessed by a dynamic
structure. E.g. only providing for the number of objects that actually
exists, or even the number for which we care about the flux. If that's
the case, then the main thing to specify is how that data is structured.
It could be structured the same in a binary output file.

27 Sep 07

Flux data might be structured as follows:

Level	Description					Name	No of values
0	Number of objects for which data is stored.	nof		1
0	Address of object header starts.		iof(nof)	nof

1	Number of quantities stored for this object.	nqf		1
1	Address of quantity starts.			iqf(nqf)	nqf

2	Number of positions for this quantity.		npf		1
2	Quantity descriptors/positions			qdf		npf

3	Timesteps							1

----- End of header----

3	Flux Data of quantity (nqf)					npf

When addressing a place to write flux data it is:

buff(time0+(time-1)*sum_{nof}(nqf*npf)+sum_{iof}(nqf*npf)+sum_{iqf}(npf)+ipf)

Thought again about using HDF5. However, this is really a library. There
does not seem to be any intention for it to be a data structure API for
simple programming. Therefore the only real reason for using HDF5 is to
make the data portable to someone else's calling of the HDF5 libraries.
That's not really what I am looking for. The principles of HDF5 do
embody some of what I am looking for: self-describing data strutures etc.

Perhaps we could reasonably choose the number of quantities to be fixed
so that we simply only need to specify the objects for which we are storing.
Then, the positions could be variable. 


29 Sep 07

Implemented structures in 3dcom.f and initializations in fluxdata.f.
Found that it was block data operating on big common blocks that caused
the very large executable. So removed that and put explicit initialization.

Implemented tallyexit in padvnc, with rudimentary particle flux counting.
It seems to work. Can subsequently obtain the fluxes.

Implement outputflux routine and corresponding readfluxfile routine to
write and read-back the flux data. 

Implement fluxdatatest to see that we really can read it back independently.

13 Dec 07

Over several days working on fedora8 have got rid of warnings. The
main actions are to turn off unused argument warnings and to edit
/usr/local/include/mpif.h to remove the save statements on the common blocks.
It ought not to be necessary to use save statements on them I think.
However, that is a peculiar usage that might be really needed, and I'll
have to watch out for it. In any case, that change did not change the
answers.

[Got extace compiled and working after installing some devel rpms for fftw
and other. Got rununfullread working.]

16 Feb O8
Fiddled a bit with the flux reading and writing.

12 Jun 09
Added documentation to 3dcom.f
Added additional possible dimensions to the position descriptor data,
because a single number might not describe the position sufficiently.
More dimensions (nf_posdim>1) does not affect the actual data averaging
since it is stored as a linear array. But the linear array might really
refer to two angles (or more parameters). 

Fix segfault bug with undefined cworka in orbit3plot.

13 Jun 09

Fixed some other little bugs.
Improved some accis routines to make the rotation of the slice plot work
more smoothly and fixed some bugs in it.

Now want to overplot the 3-D orbit on an existing perspective plot.
Issue is that a mesh has the third axis scale set to something to do
with the function amplitude rather than position. Need the ability to
rescale that axis, plot orbits, then scale back to prior. Also need
a poly3mark routine.

Instead, first modified the cijplot routine to enable choice of objects
to plot and overplot the orbits on that. This avoids any need to rescale
etc. Also made a polymark routine. 

2 July 09

Replaced the ran() function with a purely fortran one ran1 from NR. 
The reason is that we can't get at the internal state of any of the
decent built-in random generators, so we can't do proper restarts.
The time for ccpic -s20 with the old one is 
real    0m33.843s
user    0m16.358s
sys     0m0.378s
And with the new one it is
real    0m33.437s
user    0m16.306s
sys     0m0.304s
There is no detectable time difference for this single-processor case.

In partwriteread we save the random number state ranstate, and read it back
so that we can restart and get exactly what we would have got if we had
not saved the state.

At present, we do not have the mpi infrastructure for gathering particle
data from different processes or broadcasting back the field data. This
is eventually going to be needed.

Ok. Created writing of potential too. 
I think that ought to be enough to be able to restart. We have to have
identical parameters, which is currently assumed rather than written,
although iuds is stored with potential. 

Trying to get the restart going. I find that there is disagreement.
To test the rereading, I do an internal restart by jumping back into the
code after 5 steps. This gives identical results as not restarting.
This shows that everything (relevant) that is read back is being read
back correctly. However, the difference with a true restart means
that there's something in the restart that is not being set correctly 
by the reading process.

Tests based on ccpic, ccpic --restart, ccpic -s10,
with a sample psum, q, and random number show:

The psum and q difference does not start till the 8th iteration.
This is already remarkable, since it means there's no difference
for the first two iterations after restart. 

The psum/q differences start before there are any differences in the
random sample. This strongly suggests there's not a problem with the
random number generator restart.

I find that the u-differences start immediately after the first solve
of the restart. So that is where things are changing.

Probing inside of sormpi with output from individual iterations. This
shows that the differences start to show up on the second return from
sorrelaxgen0 after the restart:

 Restart files read successfully.
 nrein,n_part,ioc_part,rhoinf,dt=        1253       51915       52359   99.97294      0.1000000    
 psum sample   5.197589     u    sample -5.5481944E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9151652E-02  -2.000000      5.7159495E-02
 Return from sorrelaxgen0           2 -6.2908038E-02  -2.000000      7.9460606E-02
 Return from sorrelaxgen0           3 -3.9616335E-02  -2.000000      6.9320247E-02
 Return from sorrelaxgen0           4 -3.5938688E-02  -2.000000      6.5017469E-02


Return from sorrelaxgen0          56  2.6678543E-05  -2.000000      6.2136307E-02
 Return from sorrelaxgen0          57 -2.2355829E-05  -2.000000      5.4357897E-02
 Return from sorrelaxgen0          58 -1.8731193E-05  -2.000000      6.2133629E-02
 q    sample   1.502413     u    sample -6.0202956E-02
0006 iterations:  58 Total flux number   147.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51756  52359  99.973   0.100
 psum sample   4.499379     u    sample -6.0202956E-02  ran1  0.8549011    
 Return from sorrelaxgen0           1 -3.3089679E-02  -2.000000      5.8978312E-02
 Return from sorrelaxgen0           2  7.8395963E-02  -2.000000      6.1556634E-02
 Return from sorrelaxgen0           3  4.7830440E-02  -2.000000      6.8785459E-02

 q    sample   1.059864     u    sample -5.5481944E-02
0005 iterations:  58 Total flux number   141.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51915  52359  99.973   0.100
 psum sample   5.197589     u    sample -5.5481944E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9151652E-02  -2.000000      5.7159495E-02
 Return from sorrelaxgen0           2 -6.2949345E-02  -2.000000      7.9473235E-02
 Return from sorrelaxgen0           3 -3.9642353E-02  -2.000000      6.9339350E-02

Printing out in addition, relax, omega, xjac_sor shows difference in relax
occuring on the same return that there is a delta difference (but not omega).

 Restart files read successfully.
 nrein,n_part,ioc_part,rhoinf,dt=        1253       51915       52359   99.97294      0.1000000    
 psum sample   5.197589     u    sample -5.5481944E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9151652E-02  -2.000000      5.7159495E-02
   1.000000       1.000000      0.9957700    
 Return from sorrelaxgen0           2 -6.2908038E-02  -2.000000      7.9460606E-02
   1.890094       1.983257      0.9957700    
 Return from sorrelaxgen0           3 -3.9616335E-02  -2.000000      6.9320247E-02
   1.876438       1.967066      0.9957700    

 q    sample   1.059864     u    sample -5.5481944E-02
0005 iterations:  58 Total flux number   141.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51915  52359  99.973   0.100
 psum sample   5.197589     u    sample -5.5481944E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9151652E-02  -2.000000      5.7159495E-02
   1.000000       1.000000      0.9957700    
 Return from sorrelaxgen0           2 -6.2949345E-02  -2.000000      7.9473235E-02
   1.891335       1.983257      0.9957700    
 Return from sorrelaxgen0           3 -3.9642353E-02  -2.000000      6.9339350E-02
   1.876438       1.967066      0.9957700    

Yes, there seems to be a difference in oaddu. Perhaps this is arising from
the previous solution because there does not seem to be an initialization of
dden. Consequently the dden is what is left over from before. That will make
the prior test solution give a difference, since oaddu is 0 for it. This seems
to be the cause:

 Restart files read successfully.
 nrein,n_part,ioc_part,rhoinf,dt=        1253       51915       52359   99.97294      0.1000000    
 psum sample   5.197589     u    sample -5.5481944E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9151652E-02  -2.000000      5.7159495E-02
  7.3466018E-02   1.000000       1.000000      0.9957700    
 Return from sorrelaxgen0           2 -6.2908038E-02  -2.000000      7.9460606E-02
  7.2402194E-02   1.890094       1.983257      0.9957700    
 Return from sorrelaxgen0           3 -3.9616335E-02  -2.000000      6.9320247E-02
  7.2402194E-02   1.876438       1.967066      0.9957700    

 psum sample   5.197589     u    sample -5.5481944E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9151652E-02  -2.000000      5.7159495E-02
  7.2402194E-02   1.000000       1.000000      0.9957700    
 Return from sorrelaxgen0           2 -6.2949345E-02  -2.000000      7.9473235E-02
  7.2402194E-02   1.891335       1.983257      0.9957700    

Yes, changing to ensure that it is properly initialized fixes this:


 Restart files read successfully.
 nrein,n_part,ioc_part,rhoinf,dt=        1253       51915       52359   99.97294      0.1000000    
 psum sample   5.197598     u    sample -5.5441111E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9148662E-02  0.1710546       1.000000    
 Return from sorrelaxgen0           2 -5.9492927E-02  0.1805826       1.787417    
 Return from sorrelaxgen0           3 -3.5247445E-02  0.1702435       1.765143    


 q    sample   1.059865     u    sample -5.5441111E-02
0005 iterations:  43 Total flux number   141.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51915  52359  99.973   0.100
 psum sample   5.197598     u    sample -5.5441111E-02  ran1  0.8150202    
 Return from sorrelaxgen0           1 -2.9148662E-02  0.1710546       1.000000    
 Return from sorrelaxgen0           2 -5.9492927E-02  0.1805826       1.787417    
 Return from sorrelaxgen0           3 -3.5247445E-02  0.1702435       1.765143    

It also seems to lead to smaller number of iterations. Which is also good.

However, it has not solved the later divergences. They start after the 6th
iteration, which is completed without divergence. How can that be?
The difference first observed is in delta.

 Return from sorrelaxgen0          44 -1.9401210E-05  0.1755715       1.662254    
 q    sample   1.502416     u    sample -6.0158029E-02
0006 iterations:  44 Total flux number   147.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51756  52359  99.973   0.100
 psum sample   4.499377     u    sample -6.0158029E-02  ran1  0.8549011    
 Return from sorrelaxgen0           1 -3.3093132E-02  0.1704593       1.000000    
 Return from sorrelaxgen0           2  7.4114323E-02  0.1755701       1.787982    

 Return from sorrelaxgen0          44 -1.9401210E-05  0.1755715       1.662254    
 q    sample   1.502416     u    sample -6.0158029E-02
0006 iterations:  44 Total flux number   147.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51756  52359  99.973   0.100
 psum sample   4.499377     u    sample -6.0158029E-02  ran1  0.8549011    
 Return from sorrelaxgen0           1 -3.3690698E-02  0.1704593       1.000000    
 Return from sorrelaxgen0           2  6.2475450E-02  0.1755701       1.787982    
 Return from sorrelaxgen0           3  4.0570423E-02  0.1725774       1.769773    


 q    sample   1.502416     u    sample -6.0158029E-02
0006 iterations:  44 Total flux number   147.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51756  52359  99.973   0.100
 psum sample   4.499377     u    sample -6.0158029E-02  ran1  0.8549011    
 Calling sorrelaxgen   0.000000       0.000000       1.000000    
 Return from sorrelaxgen0           1 -3.3093132E-02  0.1704593       1.000000    
 Calling sorrelaxgen   0.000000       0.000000       1.787982    
 Return from sorrelaxgen0           2  7.4114323E-02  0.1755701       1.787982    

 q    sample   1.502416     u    sample -6.0158029E-02
0006 iterations:  44 Total flux number   147.0000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51756  52359  99.973   0.100
 psum sample   4.499377     u    sample -6.0158029E-02  ran1  0.8549011    
 Calling sorrelaxgen   0.000000       0.000000       1.000000    
 Return from sorrelaxgen0           1 -3.3690698E-02  0.1704593       1.000000    
 Calling sorrelaxgen   0.000000       0.000000       1.787982    
 Return from sorrelaxgen0           2  6.2475450E-02  0.1755701       1.787982    


I think it pretty much has to be an internal state of sorelaxgen. Because
all the parameters are set to be the same going into it. Unless something
very bad has happened with u or q.

3 Jul 09

It is the seventh iteration first call to sorrelaxgen that goes awry.
Perhaps the red-black iteration is the problem? It is controlled by the
value of k_sor which is the same. Hard to see it. We need a better way
of detecting the difference.


 psum sample   279.4092     u    sample   0.000000      ran1  0.2056652    
 Calling sorrelaxgen   0.000000       0.000000       1.000000    
 Return from sorrelaxgen0           1 -7.8246323E-03   2.635117       1.000000    
 Calling sorrelaxgen   0.000000       0.000000       1.070949    
 Return from sorrelaxgen0           2 -8.1036519E-03   2.636601       1.070949    
 q    sample   1.000000     u    sample   0.000000    
0005 iterations:  14 Total flux number   51.00000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51906  52359  99.973   0.100

Created a checkdelta routine inside sorrelaxgen to read an old file of
deltas and check the current value against it. The files have to be swapped
after the run: mv checknew checkdelta.

I find that even subsequent identical runs do not agree. There are
small differences in the low order bits of the delta. This seems to show
either that there are truly random bit-level errors or that there's
something wrong with the initialization that prevents exact repetition.
The differences arise even in the initial test solution before any
particles have been added. Strangely, there's zero difference in the particle
solutions etc. So I don't understand how there can be delta differences.

Called ran1(-1) earlier to make sure the volumes are the same on
different machines. Found it gave a segfault. IDUM was being set
incorrectly in ran1. Stopped that. Also made the subsequent setting
call -myid-1 to ensure that it's really negative.

With optimization turned off we are getting bigger differences in the 
first solve. And subsequently smaller and smaller differences. I'm not
sure whether that's significant. Still the difference early in the
first solution are not small, and in general the first iteration is
showing it. These are not rounding errors. They appear to be random
initialization differences.

Found that I was not initializing the u to zero (or anything). This
was apparently the cause of the differences. Fixing it got rid of the 
delta differences. But that has not fixed the restart. 

Tried checkuqcij on some different step numbers. Found that step 6 is fine
but that going into the sormpi on step 7 there are q differences (very slight).
How can that be? 

After long struggles with passing errors and segfaults, got testing of
uqcijpsumvolumes going. It shows that after a restart the psum is different,
pretty much everywhere by a moderate amount. The qs are different too, but
not on the boundary (where presumably they are not set). Again this is the
_second_ step after the restart. In other words the first step has caused
the psums to start to differ. They did not differ immediately after
the restart. This check is going into (right before the sormpi call).
So we can't tell if this difference is coming from sormpi. So put the call
right _after_. The answer is that the first uqcij checks fine. Thus the
first sormpi call is working correctly. Consequently it must be the first
particle move that is giving errors. However, putting after padvnc does
not show differences till the second test. Putting after the chargetomesh
shows differences on the second cycle. This is consistent with the particle
move giving differences that are transferred to psum at the first subsequent
chargetomesh. 

We rely on the partlocate in chargetomesh to keep current the mesh position.
Although we save it and restore it, it is the updated by chargetomesh. 

Printed out a sample of the x_part values immediately after the (first)
advance. There's no difference. That's a puzzle:

 Calling sorrelaxgen   0.000000       0.000000       1.072827    
 Return from sorrelaxgen           2 -9.6360259E-03   2.613914       1.072827    
 q    sample   1.000000     u    sample   0.000000    
0006  15 iterations. x_part sample   2.396352     -0.6855422      -3.690475      -1.057408      -1.120257     -0.6776624       4.751034       3.213245       1.688664     -0.4781322       2.480651       2.000758     -0.8974879      0.2682267      0.2117976       3.305810       4.726902       4.489779    
 Total flux number   42.00000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51802  52359  99.973   0.100
 ***** psum difference           2           1           1  7.6883718E-02  7.7840298E-02
 ***** psum difference           3           1           1   1.262272       1.280330    
 ***** psum difference           4           1           1   1.013222       1.011209    
 *

 Calling sorrelaxgen   0.000000       0.000000       1.072827    
 Return from sorrelaxgen           2 -9.6360259E-03   2.613914       1.072827    
 q    sample   1.000000     u    sample   0.000000    
0006  15 iterations. x_part sample   2.396352     -0.6855422      -3.690475      -1.057408      -1.120257     -0.6776624       4.751034       3.213245       1.688664     -0.4781322       2.480651       2.000758     -0.8974879      0.2682267      0.2117976       3.305810       4.726902       4.489779    
 Total flux number   42.00000    
nrein,n_part,ioc_part,rhoinf,dt= 1253  51802  52359  99.973   0.100
 ***** psum difference           2           1           1  7.7840298E-02  7.6883718E-02
 ***** psum difference           3           1           1   1.280330       1.262272    

They start to deviate very slightly the next step. But in reality if the 
positions of the particles are the cause of the problem, I don't see how they
can be exactly correct after the first push. 

Implement xpartcheck. I find that there are differences in x_part during
the second iteration, before chargetomesh. That is, I confirm differences
after the first particle push, for particle 29 47 54. The velocity differences
are large. Order unity. The position differences are small. Seems to imply
that the acceleration is where there's an error. There's nothing obviously
systematic about the particles with differences. 

Did check with uqcij right before padvnc and xpart right after. The xpart
diffs are present, not uqcij. Thus we've proved there are advancing differences
when there are no uqcij differences. Since no if_part differences appear,
that's clean. The 6-9 x_part values, which are the mesh fractions, are not
in error the first time. But by the third time, they are. Thus, we are 
not calling partlocate. These are not newly injected particles.

This is tough. Construct a diagnostic version of padvnc. It reports the 
value of i and field for the first 100 particles. I see that the particles
with differences are reported twice. That is they are going through
the routine a second time. This is because inewregion is being returned
as 3.

ccpic -s8
          28 -1.6265622E-03 -9.0324413E-03 -3.8206729E-03           2           2
          29 -1.8644669E-03 -6.8034087E-03  2.6758902E-03           2           3
          29 -1.5171642E-03  4.0289122E-03  2.4152363E-03           2           2
          30 -8.1677195E-03 -2.4931235E-03 -1.4990305E-04           2           2

ccpic --restart
          28 -1.6265622E-03 -9.0324413E-03 -3.8206729E-03           2           2
          29 -1.8644669E-03 -6.8034087E-03  2.6758902E-03           2           3
          29 -1.5171642E-03  4.0289122E-03  2.4152363E-03           2           2
          30 -8.1677195E-03 -2.4931235E-03 -1.4990305E-04           2           2

It appears that the field is actually being evaluated the same both times.

-s8
          29 -1.8644669E-03 -6.8034087E-03  2.6758902E-03           2           3
 Reinjected          29  0.5868658      -4.671297       1.682282      0.2139225       1.030760      -1.000355       3.793430       1.164375       4.341133      2.3144661E-02   0.000000             110           3           1           4  0.7934299      0.1643748      0.3411326               2
          29 -1.5171642E-03  4.0289122E-03  2.4152363E-03           2           2

--restart
          29 -1.8644669E-03 -6.8034087E-03  2.6758902E-03           2           3
 Reinjected          29  0.5868658      -4.671297       1.682282      -1.054011       1.133722     -0.2721342       3.793430       1.164375       4.341133      2.3144661E-02   0.000000             110           3           1           4  0.7934299      0.1643748      0.3411326               2
          29 -1.5171642E-03  4.0289122E-03  2.4152363E-03           2           2

The differences are in the 4-6: velocities reinject is giving the particle
different velocities, although the same positions. The velocities are got 
from gasdev.

GASDEV in randf.f was calling ran0 not ran1. Thus it was giving different
velocities. This problem arose because I did a grep on ran0 not on RAN0.
Argh! So I lower-cased the routine names there to prevent future problems.

Fixing that, I seem to get the right answer. No I am getting x_part 
differences for particle 2 (only). 

restart:
0006  15 iterations. ====== Finished uqcijckeck
           1 -1.2301615E-02 -9.4538052E-03  3.2518448E-03           2           2
           2  1.0301614E-02 -2.0927475E-03 -2.7766897E-04           2           0
 Reinjected           2  -1.689946      0.6363239      -4.662046     -0.2221324      -2.588727      0.2661515       2.655035       3.818159       1.169000    
           2 -2.2906796E-03 -2.6510621E-03  2.6147573E-03           2           2


s8
0006  15 iterations. ====== Finished uqcijckeck
           1 -1.2301615E-02 -9.4538052E-03  3.2518448E-03           2           2
           2  1.0301614E-02 -2.0927475E-03 -2.7766897E-04           2           0
 Reinjected           2  -1.689946      0.6363239      -4.662046      -1.117069      -2.251752      0.6365508       2.655035       3.818159       1.169000    
           2 -2.2906796E-03 -2.6510621E-03  2.6147573E-03           2           2

There's another problem. gasdev has internal state information so the first
calls to it are broken. Make the internal state of gasdev available in 
ran1com and include it in the save and restore. Yes. Now we are getting
identical results.

Summary of Restart Facility and Experience.  4 Jul 09
------------------------------------------- 

Code now restarts and gives exact numerical agreement with runs that
simply had more steps in the first place. The key problems were
associated with random number generators. 

I found that dden was not being initialized properly in
sormpi. Correcting that also reduced the number of iterations. [I
think that Leonardo noticed a problem that might be this.] Another
problem found was that u was not being initialized to zero.

A day-long search tracked down the fact that (1) gasdev was calling
the old ran0, not ran1, and also (2) needed its internal state saved.
With that fixed we have exact agreement.


Had a problem with the cvs commit. Wireless broke in the middle. Hope this
is going to work. But it does not seem to do so. 


7 Jul 09 Restart is still not right. 

We get Getfield no good vertices errors. This is because all fractions
are zero. We ought not to be using these slots somehow.  I think the
reason is that pinit initializes all slots up to 52359 but when run
for long enough, ioc_part drops below this. (That did not happen for
my short test ./check) Consequently when we read back, we don't write
over the slots that have been reinitialized, and so the code thinks it
is ok to use them but it's not.  The fractions are not set in
pinit. Perhaps they should be. But perhaps this is fortuitous because
it has shown me an error that might not otherwise have been obvious.

In partread zeroing the flag of slots higher than ioc_part stops errors.

8 Jul 09

Multiprocess calls don't work. On TP400.
There, I've installed the latest MPICH2 from source. Things then compile.
I've fiddled inside bbdy but that's not the cause (I'm pretty sure).
Yes verified that by getting back the cvs mpibbdy and doing a 2 process
run, which crashes.

         call MPI_BARRIER(MPI_COMM_WORLD,ierrmpi)
         stop
helps to localize where the crash occurs. If it happens before this,
then you don't get much output. If not, then you get all output up
to this. 

The crash appears to occur on the second call to sormpi. This is the first
time that communication is occuring. I've heard that mpd does not work
when the hosts resolve to 127.0.0.1, which is the case for me now.
Tried some other mpd.hosts lists, but they give "failed to handshake".
Can't even get the tp41 working. 

Turns out the result of $hostname must be the same, on either machine.
It does not crash on tp41 with -n 2 and blks=2. So we are looking for 
something tp400 dependent.
Checked out the cvs to tp41. It runs with two processes. Yep it's tp400.

Got the alltoallw.f test program. Compiled. It seems to work. Does not
crash. Yes, it makes sense (after some puzzling). Therefore we seem
not to have an inherent communication problem. It's really a problem
inside sormpi. And in fact the mpd stuff all works with the hostname
set to tp400-64.

SCP the new mpibbdy.f to tp41 make. It runs two processes correctly,
with no relevant code differences to here. It is the tp400. 

The code mpibbdytest.f is also broken. This is probably easier to
debug. I can see that communications are correct till the gather. 
Then crash.

9 Jul 09
Figured out the problem finally by doing some tests on Loki.

The problem lies in the routine MPI_TYPE_CREATE_HVECTOR or the older version
MPI_TYPE_HVECTOR. In many man and web pages MPI_TYPE_HVECTOR is said to be
obsolete and to be replaced with MPI_TYPE_CREATE_HVECTOR. See for example
http://linux.die.net/man/3/mpi_type_hvector and
http://linux.die.net/man/3/mpi_type_create_hvector

However, these calls are not identical. In particular the argument STRIDE is
simply INTEGER in MPI_TYPE_HVECTOR but in MPI_TYPE_CREATE_HVECTOR it is:

INTEGER(KIND=MPI_ADDRESS_KIND) STRIDE

I was not declaring STRIDE explicitly (I called it iSTRIDE). Therefore it was an
INTEGER. On a 32 bit machine, INTEGER is 4 bytes long, the same as
MPI_ADDRESS_KIND. On a 64 bit machine (in linux) an INTEGER is still 4 bytes
long, but MPI_ADDRESS_KIND is 8 bytes, and so CREATE code breaks.

I discovered this by accident because on Loki there is no
MPI_TYPE_CREATE_HVECTOR, for reasons I still don't understand. So we replaced
the call with MPI_TYPE_HVECTOR there. When I did the same on my 64 bit laptop,
my code worked, after which the explanation above became clear. Especially
helpful was the page

http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=/com.ibm.
cluster.pe510.mpisub.doc/am107_itchvec.html

It turns out that gfortran recognizes the above KIND construct (not F77). So I
can obey the advice to use MPI_TYPE_CREATE_HVECTOR. Alternatively I can NOT
define iSTRIDE and use MPI_TYPE_HVECTOR. Either works with the correct
declaration.

Tried replacing the sceptic mpibbdy.f with the new fixed one. It gives
identical results. But perhaps I am not using the right switches to 
exercise it.

Probable next steps. Communication of the particle data through MPI.
Most of what else I had previously planned is done.

12 July

Starting on particle gathering. We need a block structure for exchanging
all the data for the whole used array, for example for psum or q.

It makes sense to use the bbdyblockcreate routines to do this. 

First change the iside(imds,2) to iside(2,imds) so that we don't have
to have imds everywhere, rather we can pass ndims, and use that for the
second (but not first) dimension. iside occurs only in mpibbdy.f, as
does bbdyblock. So it appears that's the only file we need to fix.
Now imds is used only in the top level bbdy routine. Not in the block
creation routines.

These and other complications arise because the existing code has
built in two types of block length, bulk and top. Also tuned up the
resetidim code to choose better match to prescribed nprocesses.

Packaged the construction steps for the alltoallw types into routine:
bbdygatherparam. This helps to contain the issues. 
It seems to show that we really only need a call to bbdyblockcreate.
Then the bulk handle for dimension n is at ktype(2**n).
If we put iside(2,id)=0, then we will get a negative count, because
the pass does not include the boundaries, even though the length appears to.
Thus one should presumably pass q(2,2,2) but with iside equal to iuds.
This is confirmed in that iside is calculated from the difference
in origins but with 2 added. 

There's another issue to do with chargetomesh. It puts the charge onto
adjacent nodes without consideration of boundaries. That's not really right.
Checking inside volint, I currently set volumes taking account of the 
mesh boundaries. Vol is set to a large number outside region which will
divide the density down to zero. Vol is set to a corrected number for
a node with intersections. Seems as if this ought to work. So perhaps theres
no problem. If so then we just need the reduce with the correct structure.
There might be a problem with gradient at the boundary. This would mean
the BC is effectively not second order accurate. 

13 July 09

I discover that I have misunderstood the REDUCE capabilities. In order
to operate on a customized MPI datatype, one has to write a customized
operator. So even though I can create a datatype that refers to the 
block iuds(ndims). I can't reduce it unless I have the operator. 
Operator has to be of the form
	 user_function(invec,inoutvec,len,type)

In my case I'd be passing only one dataobject. So I'd have to know
internal to the function, the structure of the calculation required,
e.g. add up the active elements.

Alternatively, if I keep it simple and reduce the whole arrays, regardless
of how much is active, there are inefficiencies. E.g. if only half is used
in each dimension, the inefficiency is 2**3 = 8. How does this compare with
the other communications? Well the boundary exchanges take place more 
often: iterations x more. But they are smaller, because they are only 
faces, not volumes. The number of iterations is probably at max a few
times the linear dimension. So the total communications for a solve
is a few times a total volume. If that's right, then we are comparing 
few x volume with (e.g.) 8 x volume. The reduce is going to be more important
than the total solve communications. It is worth trying to minimize it.
Or else just never using subarrays would make life WAY easier.

The user_function has to know by common: ndims, iLs and iuds (or ium2)
It might do an mditerarg, in which case ifull is needed rather than iLs.

Wrote a user_function using mditerarg. It seems to work. There's an 
error using MPI_IN_PLACE with MPI_REDUCE, but not with MPI_ALLREDUCE.
I suspect that this can only be used by the root (for some stupid reason).
It does not do anything for the non-root in a REDUCE call, but IMHO ought,
nevertheless to work, for consistency. It doesn't.

Packaged the function all up into a decently easy call and moved it
into mpibbdy.f. mpibbdytest shows it working.  Commit.

Put ALLREDUCE of nrein and phirein into rhoinfcalc. This should be 
sufficient to satisfy the partcom reduce requirements. We need to
figure out the normalization and defaults for ninjcomp/nrein etc.

Found that I had to do the allreduce on psum so that psumtoq set
the external phi correctly to compensate for the electron density
which it otherwise did not for multiple processes.

Got phiexamine routine going to examine the potential after the run. 

We need a potential interpolation routine that works at the boundary.
We seem only to have a field interpolation routine at the moment.
Potential ought to be easier, but I don't know how it should work off hand.

If I did not set there to be a discontuity in phi at the edge, it might be
easier to do the interpolation sensibly. It is certainly possible to 
prescribe sphere type 1 instead of 257, which then gives a profile that
could be more easily extrapolated.

Deep thought. This is not a trivial issue. 

18 Jul 09

Built a getpotential function that does multilinear interpolation if all
the nodes are present, else falls back to another approach. At present
just uses the closest valid point. Probably not quite as good as using
a continuous phi, but should work without. Need a way to test this. 
Intend to use stencil extrapolation as the better solution, which will
also need testing.

Had an idea that I could calculate the cut volumes a lot quicker by
doing a geometric integration from one vertex (or actually anywhere in
the cell) along lines. Finding the nearest place where these move out
of the cell would be reasonably easy (bisection). This would work
correctly for cell shape that was convex. Concavity might mess us
up. For that the monte-carlo approach might be more convincing. But I
doubt if concave surfaces are usual. And we probably could avoid the
issues by specifying a particular direction for lines.

We currently use 10000 MC points which requires ndims*10000 random
numbers and 10000 insidealls. I could imagine getting decent results
from a 10x10 grid of lines each of which has to have its ends found to
(say) 1% accuracy. 1% accuracy by bisection requires about 8
insidealls (times two ends). But probably one could avoid a lot of
those calls by starting the end search at the boundary wall, which
will usually be correct. I'd guess, then that each line integration 
will cost on average more like 4 isidealls. In which case our costs are
going to be in the vicinity of n1 x n2 x 4 insidealls. Thus even if the 
insidealls are the main cost and rand is not (which is optimistic), there's
the opportunity for perhaps a factor of 10 win by going to n1=n2=15 which
ought to be fully satisfactory. In the very long run, an improvement of this
order is required if one is to contemplate a moving boundary that needs
its volume recalculated at each step. Such a situation might also call
for parallelization. 

20 Jul 09

Implemented getpotential multilinear interpolation
with two types of filling in of missing points:
1. Just set equal to the nearest point value.
2. Calculate gradients locally from nearby present points. Then fill in
by extrapolating from the value at the centroid. 
Added a phi plot to -gt

Type 2 is sometimes a lot better than fill type 1. However, it is basically
the same when we are on an axis, because then the type of absent points
is such that one face is absent in total. The gradient in that direction
can't be calculated and is taken by default to be zero. Thus cases with 
one whole face missing are almost as bad as the simple nearest point fill.
In a case like that, we must use more information.

I realize that I could use getfield (or some form of it) to obtain the 
gradient, rather than using the box vertices. This might be a more reliable
way to do it. But I'd still need an average or some other value to 
extrapolate from.

21 Jul 09

Very nearly got something working with a fallback to get the field at
the point if we fail to find the gradient from the existing box points.
However, there seems to be a bug. I think it is that it is possible to
set a box vertex that is actually on the other side of an interface 
as being present in the region, if it does not have a pointer set 
(i.e. it is not itself adjacent to the boundary). That gives a big error
when it happens, at the edge and -at2.1. It is certainly possible for
opposite vertices, even in 2-D, to suffer this problem. Consequently,
my implicit assumption that a vertex with pointer not set is in the right
region, is wrong.

This seems puzzling because cijroutine seems to be written such as to
fill in all vertex pointers that have crossings within any of their
boxes. However, the text3 plot shows that that is not happening.
Actually there's some code in cijroutine that is said to drastically
reduce the number of boxes counted. Perhaps that's ultimately the
cause.  For the standard mesh, it reduces the number of pointers from
14k to 11k. So the storage reduction is definitely not worth it.
Anyway removing that test and using the increased pointer count
fixes the bug, making my assumption correct. A 60x60x60 grid with
about 200k point uses about 50k pointers. Which by the way makes cij
objects almost as important as cij itself.

As anticipated, fillin gets a field value on average less than once
per call. So the cost of extra extrapolation is pretty acceptable. 
There are still some peculiarities at the mesh edge in the outside
region. We are getting the wrong field value. It ought to be zero
but it is not. Probably there's an issue with the cij values for
this type of BC. Actually, I don't see how I can correctly do the
extrapolation from the mesh edge. Because I think the point beyond
will be used. That's an issue. Maybe that's ok because of the cij facts.

Print out the maximum phi and grad phi errors for different grids.

grid  	  at?     solution	   phi      gradphi
16x16x10   .9	  3.62e-2	   -.330    0.376
16x16x10   --	  ''		   .385e-2  0.724
16x16x10   .5     ''               .411     0.272
16x16x16   --	  4.0e-2	   .199	    0.35
	   .5	  		   .223	    0.156
	   .9			   .256	    0.100
32x32x32   --     6.2e-3	   .27e-2   0.163
           .9	  		   9.7e-2   0.453
	   .5			   .105	    0.347
64x64x64   --     2.00e-3	   6.6e-3   1.69e-2
	   .9	  		   2.2e-2   8.8e-3
	   .5			   3.1e-2   3.0e-2
128^3	   --     1.61e-3          4.8e-3   2.68e-2
	   .5	  		   2.1e-3   3.5e-2
	   .9			   5.9e-3   4.6e-3

There are sormpi convergence issues with this the 128^3. Fiddled but not
great. 

It's not terribly obvious from these maximum errors what the convergence
is. The gradphi seems horrendously noisy. Phi does not seem quite so bad.
The domain is 10 in diameter, so the ratio of sphere radius to cell size
is 10/L. To have field errors that are of order a percent when the ratio
of characteristic size to cell is ~10 is consistent with second order
convergence, although things don't blow up as badly as you might expect.
32 is pretty bad. 

23 Jul 09

Convergence is pretty slow for the 128^3 case. Looked into the SOR.
Remember that the k_sor count is half-steps (red/black). So it is not
as bad as it looks. The biggest problem is that the omega gets too big
in the initial Chebychev acceleration calculation. It ought to be a
bit lower but I have not changed it as of now. The convergence can be
tweaked a bit but the omega choice is pretty good. I think the only
realistic way to improve it would be to do dynamic adjustment based on
actual response.  That would need more programming than I care to
devote at present.  When lambda is less than about 1, there is a
dramatic reduction in number of iterations. When lambda is greater
than about 50, there is also a dramatic reducion after the first solve.

Next we need to get the reinjection to a point where we can really compare
some cases with sceptic. At present we just have Gaussian reinjection.
We worked on getpotential in order to be able to calculate the averein
potential. Checked sceptic2 paper to see how good we need to be. 
Looks as if there's going to be an issue at intermediate lambda unless
we adopt the complicated reinjection schemes of sceptic.

The sceptic schemes are contained in

REINJECT=fvinject.o orbitinject.o extint.o maxreinject.o ogeninject.o

Of which the maxreinject has no drift. fvinject is for collisional
distribution functions, ogeninject is for gyrotropic distributions.
orbitinject is the standard form. If we hack the orbitinject file
to remove the fv, max, ogen references, then with
REINJECT=orbitinject.o extint.o
it compiles and runs. Therefore, it appears I could use this.
extint contains the netlib exponential integral function(s).
oreinject(i,dt) is the call to reinject. The main issue is the use
of piccom.f which has a load of stuff in it that I don't want.
I need to cut down those needs and rationalize the parameter passing.
The only thing that needs the reinject.f code is the test routine
fvinjecttest, and it does not actually call it, it just needs it for
advancing.f, I think. 

orbitint program tests the stuff, but it seems also too dependent on
piccom.f and sceptic calls to be useful. 
Made a version of orbitinject with implicit none. Seems to work in
orbitint. This makes clear all the locally defined variables.
Anything else is a reference to the common variables.
Then commenting out the include piccom.f should reveal those.
Ok did that an put in dummy declarations.

oreinject
c We put here the declarations that are needed to fix excluding piccom.
      real xp(6,1)
      real averein,debyelen,fluxrein,pi,spotrein,Ti,vd
      real Vcom
      logical lcic,localinj
      integer nthsize
      parameter (nthsize=2)
      integer nr,nrein,nrfull,nrused,nth,nthused
      integer nrsize
      parameter (nrsize=2)
      integer nvel,ntrapre
      parameter (nvel=2)
      real r(nrsize),th(nthsize),phi(nrsize,nthsize)

      r( is used only for determining the wall radius.
      nr is ditto.
      th( is used only for inverting to find th coord for phihere.
      phi( is used only for phihere.
      nrfull ditto. nrused ditto.
      nrsize is unused.
      nthsize is used only in the common below.

We also find that the following common is dependent on piccom
but only occurs in oreinject routine. 
c Testing
      real vdist(nvel)
      real tdist(nthsize)
      real crdist(nthsize),cidist(nthsize)
      common/rtest/crdist,cidist,tdist,vdist

oinjinit
c To fix exclusion we need
      real Vcom(1),pu1(1),pu2(1)
      real Ti,vd,pi
      integer myid,nvel

pu
c needed from common:
      real averein,Ti,pu1(1),pu2(1)

alphaint
c needed from common:
      real adeficit,averein,debyelen,Ti
      integer nr,ninner,diagrho(1),r(1),rcc(1),diagphi(1)

  diagrho( is used only in
           if(diagrho(1).eq.999.)then

  rcc( and diagphi( and ninner are used only in
            if(ninner.gt.iqsteps)stop 'Alphaint Too many r-cells read.'
            do i=1,ninner
               qp(i+1)=1./rcc(ninner+1-i)
               phibye(i+1)=diagphi(ninner+1-i)
            enddo
So none of the above are important if we are not signaling a special
case using diagrho(1) in a kludgy way. Actually it is a signal that
we read a file in in orbitint. Completely unneeded for most use. 

  r( is used only in 
            call initext(iqs,qp,phibye,phiei,r(nr),xlambda)

Now the plan is: construct a different common declaration that together
with existing ccpic declarations will satisfy the needs and allow
testoij to run properly. plascom.f has 
	common/plascom/debyelen,Ti,vd,rs,phip

averein and adeficit don't exist.

Start reincom.f with the random interpolate data from piccom.
      nvel, nQth
      common /rancom/Gcom,Vcom,Qcom,pu1,pu2,Pc,infdbl,bcphi,bcr

Add averein, adeficit, fluxrein, spotrein, myid, ntrapre

Comment out the 999 region. Replace r(nr) with rs. That satisfies
alphaint, pu, oinjinit.

In oreinject
Comment out rs declaration, and setting of it. It's already set.
Remove r( using rs. Remove nr.

Convert phihere section to a function. Get rid of th, phi, nrfull, nrused.
Define nthsize=201 in reincom.f for the commons same as piccom.f. 

We still need nth, nthused which appear in 
      if(LCIC)then
         icr=(1.+crt)*0.5*(NTHUSED-1) + 1.5
      else
         icr=(1.+crt)*0.5*(nth-1) + 1
      endif
In LCIC cases in orbitint, 
   	      nth=nthsize-1 nthused=nth nthfull=nth+1
In non.LCIC   nth=nthsize, nthused=nth-1 nthfull=nth
In sceptic, nth is set by command line. So how do we fix this?

Made two more parameters depended upon nthsize that fix this to the 
LCIC case.

To get a test going with the testoij code we need to deal with
averein, adeficit, fluxrein, spotrein ...

fluxrein and spotrein are set by orbitinject, but never used by orbitint.
So nothing needs doing.

averein is set by orbitint and not by orbitinject, except in the code that
has been commented out in testoij. So we just need to set it differently.

adeficit is default set to zero by orbitint and only set by commented out
code in orbitinject. So we need to zero it differently. 

ntrapre is not used.

nrein is used by orbitint after orbitinject is called, for normalization.
it is incremented by ilaunch each time, which might be bigger than one.
We need code to get it back.

Summary we need: avereinset(+avdeficit) and nreinget in orbitint.f.

Found rp=rs error in orbitinject.

Got orbitinttest going to the extent of completing although not 
correctly.

With further corrections, got orbitinttest working the same as orbitint.
Got rid of lcic, nthused, nth. Retain nthsize=nQth+1 for size of arrays.

Imported a version to ccpic. Got it to link by adding relevant stuff.
Segfault (as expected). There's a fair amount yet to fix in the initing
and in xp passing averein calculation, etc.

24 July 09


Found some bugs in padvnc.f. Was not correctly handling if_part on
reinjection, since it was not being set in reinject. This probably
accounts for prior particle decay. But in any case it changes
the results.
Rationalized reinject call not to pass particle number.
Corrected the rs handling to keep it equal to the sphere radius,
even though the mesh is a tad larger.

Now seems to run in a similar way with new and old reinject.
But I need a portable way to diagnose the reinjections. If it is built
into padvnc, then it will apply to every injection scheme. Probably 
that's best. 

Implemented some reinjection diagnostics and plot that are independent
of injection scheme and implemented by a simple call in padvnc. Seems
to give similar results from my two schemes: shifted maxwellian and
orbitinject. They ought to be the same here because averein is being
taken as zero at present. 

Printed out the velocity distributions because a simple gaussian comparison
is not correct. With counts peaking at 2k per box, the distributions
are indistinguishable. Conclusion: the orbitinject is working. Commit.

TIME TESTS using sceptic:

Single process 
time ./sceptic -s200 -ni900000 -nr20 -nt20 -g -f
tp400:
real	0m24.868s
unity:  
real	1m21.860s
Thats a pretty big difference. tp400 is only using one core.
It is dominated by particle pushing. 
-ni100000: unity gives 0m20.754s. and tp400: 0m6.555s.

Two identical processes doing this on tp400: 0m7.002s. unity: 0m36.481s
I.e. very little overhead on tp400 maybe more on unity.
But that's not real multiprocessing we need scepticmpi.

scepticmpi -ni100000
unity 0m41.520s, tp400 0m7.199s. Not much difference on tp400. 

sceptimpi -ni300000
unity 1m51.364s  tp400 0m20.609s

four processes -ni300000 tp400 2m10.836s !!! Wow, that's a big hit, nearly
a factor of 10! Both processors showed 50% utilization for each sceptic.
There must have been a monstrous hit from swapping. 

Quick summary:

Single processor speed difference is about 3.3 times faster cf unity head node.
Per cpu speed is about 5.0 times faster on tp400 than unity running mpi.
It is useless to run more than 2 processes on tp400.

Total cpu capacity on unity = 36x1 on tp400 = 2x5. 36 vs 10.
tp400 is about 1/4 of the total cpu capacity of unity in multiprocessing.

[But probably there are some big breakpoints.]

The Loki tests of Feb 2008 showed Loki processors to be 3-4 times faster
than unity head node. It therefore seems that tp400 is getting about the
same per-cpu speed as the Feb2008 Loki cluster. cmodws45 got about 2x slower
in 2008. 

25 July 09

Need for averein to be set.
In sceptic averein is set from diagphi, which is part of the diagnostics
and is averaged over nstepsave. So averien is time-smoothed. We would have
to save it for restart purposes. It does not make sense to average every
injection. We ought to add injection potentials to a counter and then
divide by the number added together when we complete the advancing step.
The addition should be done in diagrein. The computation might be done
at the end of padvnc. Let's use spotrein for the sum of potentials at
rein and fluxrein as the sum of reinjections. That's what sceptic uses
them for. They need to be zeroed at the start of each padvnc.

There's currently a conflict between reincom and partcom, both of which
contain nrein. I'm not sure that nrein is really needed in partcom, although
it is written and read back, and needs to be MPI reduced. As presumably
may the other accumulators. There's also a variable phirein, which is not 
currently used except in rhoinfcalc.

27 July 09

First make reincom just the extra stuff and put explicit inclusions of the
plascom and rancom headers, where needed.

Now need to rationalize averein, phirein, nrein, ninjcomp. There's no
phirein in sceptic. 

For restart purposes, anything that influences the orbits or field must
be saved and restores. nrein is set to zero at the start of padvnc. It
does not need to be saved and restored, I think. However ave/phi-rein
if averaged from step to step, will need to be saved/restored. It is more
of a field quantity than a particle quantity, in a sense.

adeficit is used in orbintinj, and in sceptic set in advancing as part
of fcalc_lambda:
c Boundary slope factor calculations:
      do j=1,NTHUSED
c Current fractional ion deficit due to collection.
c Coefficient of 1/r^2 in modified shielding equation is
c a = deficitj * r_edge^2 / \lambda_De^2
         deficitj=1-phi(NRUSED,j)/Ti -rho(NRUSED,j)
c         write(*,*)rho(NRUSED,j),phi(NRUSED,j),deficitj
         blfac1=(deficitj/debyelen**2) * redge
         adeficit=adeficit+blfac1
c BC modification is (a/r_edge)[exp(EL*r) E_1(El*r)] given by approx.
         blfac=blfac1*expE1
         blfac=alpha*blfac
         phislopeconst(j)=blfac*redge*delredge/
     $        (redge+delredge*rindex*0.5)
         phislopefac(j)=(redge-delredge*rindex*0.5)/
     $        (redge+delredge*rindex*0.5)
      enddo
c Actual a factor averaged over angles:
      adeficit=adeficit*redge/NTHUSED
      if(adeficit.lt.0.)then
c         write(*,*)'Negative adeficit',adeficit,' set to zero'
         adeficit=0.
      endif

This gets used in the boundary condition of the sor solver. I don't think
it makes sense for CCPIC to think that we are going to be changing the 
BC every step (maybe not at all). 

29 Jul 09

Implemented OML adeficit setting (only once in the stencils).
This overrides the boundary condition in the input geometry file,
but seems to give very sensible results.

Implemented infrastructure for getting averein (in reincom) and
phirein (in partcom) from spotrein, which uses getphihere. So far
getphihere gives zero and no changes of result are found. 

There's a problem with the fact that getpotential needs lots of stuff
like u, cij, etc. So it can't readily be called from reinject.
It could be called from padvnc, but padvnc does not know the ilaunch
values etc. If I add ilaunch to the reincom, then its value along with 
nrein, spotrein and fluxrein are available to reincom. Then if we
return to padvnc before doing any advancing; getpotential; and pass it
to a routine to advance; that would work. Clumsy though. 
We could take the nrein passing out of reinject if we did this, because
it would be updated at the same time as averein etc.b

This needs rationalization. 
1. We don't need to update adeficit.
2. We update the potential used by reinject once per cycle.
3. We need to average the phihere to supply this value.
4. nrein and potl needs to be incremented by an amount that depends on the 
   number of launches.

I get rid of the localinj section. Then I don't need phihere inside the 
oreinject. Get rid of the accumulation inside of oreinj. 
Pass ilaunch to reinject. So the accumulation can all be done in padvnc.
We no longer pass nrein, because we do the accumulation in padvnc.

Pass potential and ilaunch to diaginj, and therein increment spotrein.

Remove nrein and ntrapre from reincom.f. Now not needed.
Remove fluxrein and spotrein from reincom.f. Now not needed really. 
The only things that really have to be in reinextra are averein, adefict.
These are to be set (only) by avereinset and adeficitset.

Revert diaginj to not passing or calculating with phi or ilaunch.
Update phirein in padvnc. Call avereinset and adeficitset appropriately.

Seems to be working. phirein seems very stable for l>1 and very small 
for l<1.

At present I am using nrein, phirein in rhoinfcalc for calculating
rhoinfinity. It seems to be correct, but not thoroughly checked.

30 July 09

Implemented saving of rhoinf and dt per step which then allows one to 
get the flux density normalized by rhoinf 

We have a result. The OML value flux density is 1/\sqrt{2\pi}
\sqrt(T_i/T_e) (1+\chi) which for \phi=-2 is 3/\sqrt{2\pi}=1.19. We
get this value within less than 1% with large debyelength (40x40x20)
at T_i=T_e.

At lower -l flux drops, which qualitatively it should. There is some
systematic flux enhancement at the poles. The potential and density
get very noisy, and without multiple processors, it is tough to do
much about that. We also need to look at more-negative potentials. But
first off we have a decent result that verifies the orbit solver,
though not really the potential solver with finite rho. Also verify
that acceleration is working.

31 jul 09

Unfortunately this is not working. At higher probe potential only
moderate enhancement of the flux occurs. Not nearly enough for
OML. E.g. at probe potential of -10. Also there's a major difference
between running 200k particles on one processor and 2x100k on two
processors. Therefore there's a bug in MPI somewhere. The total flux
count from both processors is about 420, and it's about twice that
reported by each. Rhoinf is about 420 (too). With one processor, there
seem to be significantly more flux count, about 460. It's unfortunate that
we need to go to a fairly high step count >100 otherwise things are not
converged. 

2x100k Total flux 440, 1.65, rhoinf=430, nrein=2077
200k   Total flux 440, 2.08, rhoinf=340, nrein=3166

tells the difference. The nrein and rhoinf are printed after padvnc and
fluxreduce but before rhoinfcalc. So I think they refer to just one 
processor, since nrein and phirein are reduced in rhoinfcalc. 

I just realized another issue, although I think not one that is relevant
here, that is that if the MPI_COMM_WORLD had different processes from the
CART_WORLD, then I might end up with doing particle calculations on a
node that does not participate in the information about potential. So it
might be completely bogus. 

I have to decide what to focus on. I'll start with single processor issues.
The flux is way too low. Why? Idea: replace getfield with a coulomb force.

Do this easily in padvnc. Then get

./ccpic -ni100000 -s200 -dt0.05 -da5 -l1000
0200   2 iterations. Phirein=   -1.983818 Total flux   219.00000   2.0631711    
 Total flux   219.00000       2.0631711    
nrein,n_part,ioc_part,rhoinf,dt= 1488 100000 100000   168.939     0.050

 Average flux over steps         100         200  All Positions:   4657.2266    
 rhoinf   164.82874       Average particles collected per step:
  4.9406  4.5545  4.9208  4.8515  4.8020  4.6139  4.9604  5.2970  4.2475  4.5842
  4.2673  4.4356  4.7624  4.6139  4.4752  3.9901  4.4653  4.8119  4.7723  4.4158
  4.9802  4.9109  4.9505  4.5644  4.4851  5.0000  4.4752  4.0990  4.6832  5.0396
  4.7723  4.4653  4.1782  4.7228  4.6436  4.8911  4.9901  4.6931  4.5941  4.0792
  4.7030  4.8020  4.7624  4.7624  5.0099  4.3861  4.8119  4.5743  4.5545  4.4950
 Flux density, normalized to rhoinf   2.2484589    

For comparison, still with the coulomb force, but with -l1. instead of -l1000.

0200  36 iterations. Phirein=   -0.072735 Total flux   339.00000   3.4161470    
 Total flux   339.00000       3.4161470    
nrein,n_part,ioc_part,rhoinf,dt= 1110 100000 100000   157.937     0.050

 Average flux over steps         100         200  All Positions:   7102.1768    
 rhoinf   165.44156       Average particles collected per step:
  6.7327  7.4752  6.8020  6.9703  7.2475  7.1584  7.2475  6.6040  7.3069  7.0297
  7.0495  6.6733  6.9901  7.1881  7.5644  8.0297  7.1980  7.6832  6.6733  7.1188
  7.3663  7.1188  6.4950  7.4257  7.0099  6.4653  7.2574  7.2673  6.3366  7.0891
  6.5743  7.0891  8.0495  7.2079  7.0297  7.0495  7.1089  7.3564  6.9406  7.1584
  7.1287  6.9307  7.1287  7.1683  6.7624  6.9307  6.9109  7.4356  7.9109  6.6634
 Flux density, normalized to rhoinf   3.4161532    

That's pretty strange, since the force is always coulomb. 


Try setting phirein=phip/5 immediately before padvnc. Makes the the flux
value low although I don't understand all the output:

0200  41 iterations. Phirein=   -0.297464 Total flux   335.00000     1.766086
 Total flux   335.00000       1.7660868    
nrein,n_part,ioc_part,rhoinf,dt= 2439 100000 100000   301.893     0.050

 Average flux over steps         100         200  All Positions:   7347.1270    
 rhoinf   309.72659       Average particles collected per step:
  7.7921  7.5149  6.9703  7.0594  7.5743  7.6535  7.6634  7.3762  7.8812  7.1782
  7.4851  7.2574  7.4455  7.3960  7.0594  6.9802  7.5347  6.7030  7.4653  7.8119
  7.2871  7.3069  7.2871  7.0495  7.1881  7.2673  7.0693  7.5743  7.6832  7.4950
  7.5248  6.9406  6.9406  7.8416  7.4752  7.1683  7.5842  7.6634  7.6238  7.4455
  7.3663  7.2376  7.2079  7.3861  7.3069  7.3960  7.3267  7.1584  6.7624  6.9901
 Flux density, normalized to rhoinf   1.8876851    


sceptic run like this:
./sceptic -l1000. -nr50 -nt10 -g -ni1000000 -p-10.

gives with some extra diagnostics:

  Flux, Phiedge, Trap, ReinjFrac
  401:  2 nrein=        3047   averein=  -1.9901596      riest=   325.22070      rhoinf=   328.70486    
  402:  2 nrein=        3059   averein=  -1.9901588      riest=   326.50159      rhoinf=   328.61774    
  403:  2 nrein=        2995   averein=  -1.9901581      riest=   319.67062      rhoinf=   328.56485    
  404:  2 nrein=        3083   averein=  -1.9901574      riest=   329.06339      rhoinf=   328.34250    
  405:  2 nrein=        3083   averein=  -1.9901565      riest=   329.06348      rhoinf=   328.36053    
  4.197 -1.990  37401  0.008

This is with dt=.025, so the nrein is of order 6000 for a .05 step.
Plainly the major difference is in nrein. Actually in ccpic there are
essentially no repeat reinjections. nlost=nrein. So any changes that
are arising from edge potential must be through the velocity
distribution. Arrghh.

1 Aug 09
Found the cause of segfaults in sceptic. It was brcsq=0. Changed the 
c Reject a particle that will not reach boundary.
c Was brcsq.lt.0. which gave segfaults.
      if(brcsq.le.0.) then
         goto 1
      endif
This probably should be fixed in a couple of other places in the sceptic
code too.

Implemented mean speed diagnostic of reinjection. It does not look the 
same for sceptic and ccpic. In particular the speed of ccpic takes a step
at the value of phirein, which is wrong (should be sqrt(phirein)).
No. That was an error. I put -p10 instead of -p-10. With -p-10 we get
speed up to 2 in both. Perhaps there's another factor of 2 floating around.
To the naked eye the distributions look the same. If that is right, then
it says we are injecting correct velocities and positions.

5 Aug 09
Ran equivalent cases in sceptic and ccpic. For ni=200000, dt=.05, -p-10
-l1000
ccpic approximate numbers:
ninner=450. nrein=3100. phirein=-1.9839. rhoinf=330. 

sceptic: 
ninner=450. nrein=3080. phiedge=-1.99. rhoinf=164.

Thus the problem is with rhoinf in ccpic. It is a factor of 2 too high. 

In sceptic rhoinf comes from rhoinfcalc:
c smaxflux returns total flux in units of Ti (not 2Ti)
            riest=(nrein/dt) /
     $           (sqrt(Ti)*
     $           smaxflux(vd/sqrt(2.*Ti),(-averein/Ti))
     $           *r(NRFULL)**2 )

and in ccpic
c Calculate rhoinf from nrein if there are enough.
         chi=min(-phirein/Ti,0.5)
         riest=(nrein/dtin) /
     $        (sqrt(Ti)*
     $        smaxflux(vd/sqrt(2.*Ti),chi)
     $        *rs**2 )
         rhoinf=riest

But the expression for chi is wrong! It needs to be max(-phirein/Ti,-0.5).
We were constraining the effective phirein to be -.5, when it was really
-1.98.

With this fixed, we get flux 4.472 normalized to rhoinf. (Sceptic 4.3916).
11/sqrt(2\pi)=4.3884. So ccpic is a bit high. rhoinf=165.
This is with pure coulomb test potential for acceleration. Running with
-l100000, phirein=-1.9947. flux=4.4755. 

Full ccpic mesh potential. flux=4.4122. 
Using 400 steps instead:   flux=4.3756 (mesh). flux=4.4008 (coulomb).
Using dt=.025 4.4049 (mesh).

These numbers appear to be consistent with a flux count that is for dt=.05
400 per step times 200 steps =80000 total particles => 0.4% accuracy.


6 Aug 09
There's still a bug in the mpi code. For 2 processes we get
[tp400 CCPIC]$ mpiexec -n 2 ./ccpic -ni200000 -s400 -dt0.025 -da5 -l100000
Average flux over steps         200         400  All Positions:   17157.578    
 rhoinf   262.65146       Average particles collected per step:
  8.6119  8.1891  8.6269  8.4826  9.1791  8.4378  8.7761  8.1144  8.9701  8.6119
  8.7811  8.7164  8.0547  8.8060  8.0945  8.3433  8.5373  8.7363  8.3134  8.4179
  8.5970  8.9154  8.3234  8.6617  8.5423  8.7612  8.3831  8.6020  8.3781  8.7164
  8.4876  8.6866  8.6965  8.4925  8.4478  8.9005  8.6269  8.1791  8.6368  8.8259
  8.9900  8.7313  8.9751  8.4826  8.7811  8.4527  8.1841  8.8955  8.5174  8.2687
 Flux density, normalized to rhoinf   5.1983638    
 
 0400   2 iterations. Total flux   441.00000       5.3087544    

And the standard case:
[tp400 CCPIC]$ mpiexec -n 2 ./ccpic -ni200000 -s400 -dt0.05 -da5 -l100000
Phirein=   -1.994918
0400   2 iterations.  nlost=        4186  nrein=        4186  ninner=      419
 Total flux   861.00000       5.1920910    
 Wrote particle data to T1e0v000r05P10L1e5.000
 Wrote potential data to T1e0v000r05P10L1e5.phi
 Wrote flux data to T1e0v000r05P10L1e5.flx
 Average flux over steps         200         400  All Positions:   17160.164    
 rhoinf   264.44150       Average particles collected per step:
 17.3831 17.1393 17.1443 16.6119 18.4229 16.7662 17.6169 16.2786 17.9900 17.0448
 17.1294 17.8358 16.1493 17.7214 16.2338 16.9154 17.2786 17.3831 16.5970 16.9005
 17.1493 17.7811 16.5274 17.2687 16.7512 17.5075 16.6219 17.2488 16.6617 17.7264
 16.9900 17.2289 17.2139 16.9204 16.9154 17.6219 16.8607 16.5174 17.3333 17.7711
 17.6766 17.7413 17.7363 17.2338 17.6716 16.6219 16.5373 18.0348 16.9154 16.6816
 Flux density, normalized to rhoinf   5.1639533    

This appears to show that rhoinf is too low, because nrein is too low. 
With two processors, it ought to be about twice the one-processor value
which was 3100. Or it ought to be the same if I am only seeing one processor's
worth. Actually seems as if we are monitoring each processor separately
and then getting too great nrein?
The flux of 861 is roughly twice the ninner number of 419,
which is about right. 

One problem was that numprocs was not being set in common by the sormpi
initialization, because it is stored in partcom, which is not available.
For now, set it explicitly with an MPI call in ccpic. This seems to 
fix it, but the plotting at the end seems to break when specifying -l
switch to mpiexec.

 nrein,dtin,Ti,vd,phirein,chi,rs,numprocs=        6328  5.00000007E-02  1.00000000       0.0000000      -1.9947799       1.9947799       5.0000000               2
0200   2 iterations. Phirein=   -1.994886  nlost=        3106  nrein=        3106  ninner=         445
 Total flux   905.00000       4.2716675    
 Wrote particle data to T1e0v000r05P10L1e5.000
 Wrote potential data to T1e0v000r05P10L1e5.phi
 Wrote flux data to T1e0v000r05P10L1e5.flx
 Average flux over steps         100         200  All Positions:   18373.264    
 rhoinf   331.71246       Average particles collected per step:
 19.1683 17.9604 18.8515 18.6040 18.6733 18.7921 17.6931 18.7723 17.7525 18.5743
 17.8317 18.3960 18.5049 19.3267 17.5644 17.4158 17.9010 19.0990 18.4455 17.9406
 19.2376 18.4752 18.5941 18.0495 17.5644 18.6040 18.2475 17.8218 17.7624 18.8911
 18.2475 18.7030 18.2475 17.5644 18.2277 19.2079 18.7921 18.8515 17.9901 18.3366
 18.8317 18.9208 18.6733 18.2277 17.9802 18.1287 19.0990 17.9901 18.4752 17.6535
 Flux density, normalized to rhoinf   4.4077301    


08 Aug 09

Rationalized some of the MPI functions into psumreduce to get them out of
main and other functions. 

It appears that the first time that numprocs is required is in pinit. 
This is called before the first psumreduce. So it won't do to set numprocs
in psumreduce. To get the MPI call setting numprocs out of main
requires a plan for this. This and the finalize are the remaining calls.

Move the additional MPI routines into reduce.f. Can't cvs add because of
bad nameserver in Venice. Do it later. 

How to fix possible mismatch between cartesian communicator and particle
(MPI_world). We don't want every gather in solver to be to all the world. 
However, 

10 Aug 09
gprof shows that field interpolation dominates in particle-dominated
runs. The interp is for partlocate. Gradinterp is for getfield.

  %   cumulative   self              self     total           
 time   seconds   seconds    calls   s/call   s/call  name    
 22.96      3.44     3.44 148586924     0.00     0.00  gradlocalregion_
 15.75      5.80     2.36 37146731     0.00     0.00  getfield_
 13.82      7.87     2.07 36890568     0.00     0.00  interp_
 11.35      9.57     1.70       30     0.06     0.15  chargetomesh_
 10.21     11.10     1.53 38305999     0.00     0.00  gradinterp_
  5.64     11.95     0.85 50755040     0.00     0.00  inside_geom_
  3.14     12.42     0.47     1121     0.00     0.00  sorrelaxgen_

So the getfield is more than half of the cpu time:
-----------------------------------------------
                0.02    0.04  256163/37146731     fillinlin_ [25]
                2.34    5.34 36890568/37146731     padvnc_ [3]
[4]     51.6    2.36    5.38 37146731         getfield_ [4]
                3.44    1.53 148586924/148586924     gradlocalregion_ [5]
                0.08    0.33 37146731/37146731     boxinterp_ [14]
-----------------------------------------------
                3.44    1.53 148586924/148586924     getfield_ [4]
[5]     33.2    3.44    1.53 148586924         gradlocalregion_ [5]
                1.53    0.00 38305999/38305999     gradinterp_ [9]

By implementing a jump out of the loop in getfield when ii1=0, reduces
the time in that routine from 2.36 to 2.00, a 15% saving. 

  %   cumulative   self              self     total           
 time   seconds   seconds    calls   s/call   s/call  name    
 23.44      3.41     3.41 148586924     0.00     0.00  gradlocalregion_
 15.22      5.63     2.22 36890568     0.00     0.00  interp_
 13.71      7.62     2.00 37146731     0.00     0.00  getfield_
 12.78      9.48     1.86       30     0.06     0.16  chargetomesh_
  8.49     10.72     1.24 38305999     0.00     0.00  gradinterp_

c Probably most of the time is spent in this calculation.
            uprime= ((2.*xm+1.) * (up-u0)
     $           +(1.-2.*xm) * (u0-um))/(dx0+dx1)

This is (2xm.up-2xm.u0 -2xm.u0+2xm.um + up-u0+u0-um)/(dx0+dx1)
= (2*xm*(up-2*u0+um) +up -um)/(dx0+dx1). This might be quicker.
But it isn't. 

Summarizing the computational costs for particle mover, they are
dominated by the getfield, gradlocal, and gradinterp region costs,
which is finding the field. It does not seem possible to make 
substantial savings in this area. 


12 Aug 09

Systematic comparison of sceptic and CCPIC with:
  dt    vd     Ti     steps. -c5  -ni200000 -nproc 2 -nr50 -nt10. -p-10. 
 0.0250 0.0000  1.000  500 
								ni700000
 		Flux:		-da3		-da5		60x60x60
debylen		Sceptic:	CCPIC
.1		1.6146		1.7244405			1.6327829
.2		2.2890		2.3339274			2.2894616
.3		2.7719		2.7993238			2.7707448
.5		3.3643		3.3790596 			3.3812742
.7		3.7056		3.7201011			3.7148750
1.		3.9970		4.0019903			3.9962780
2.		4.3465		4.2363796	4.2306852	4.2459707
5.		4.3954		4.3413186			4.3627992
10		4.3775		4.3506932	4.3558187	4.3643198
		
[Note theoretical OML: 11/sqrt(2\pi)=4.3884]

It appears there might be slight systematic discrepancies at the OML
end and at the small debyelen end. The debyelen is not being properly
resolved at -l.1 because of -nr50 and 40x40x20 resolutions. Therefore
discrepancies are to be expected. In the intermediate regime the
discrepancies are ~1% or less.  This seems very encouraging.

26 Aug 09

Fix the mismatch between numprocs and the cartesian geometry by using
the MPI_DIMS_CREATE function that fits the cartesian geometry to the 
exact number of processes available, in an optimal way. It is not called
if the number of processes is equal to the idims product already. So 
by setting idims and numprocs right, one can override the function choice.

Known weaknesses/needs
1. Possibility of undefined potential (/field) when in a concave region with
no adjacent points in the region.

30 Aug 09

Filled in the 60x60x60 column above. This shows much better agreement
with sceptic at low debyelen. Better than 0.5% for debyelen<=1.  But
also seems to indicate there's a problem at large debyelen. It's not
100% certain that the problem is CCPIC. It might be sceptic (also).
mpiexec -n 2 ./ccpic -dt.01 -da10 -s500 -ni700000 -l10
gives 4.3776546, which suggests that shorter timesteps increase the 
apparent flux. This might suggest a going-through-sphere process. 
Sceptic avoids that, but CCPIC does not. 
mpiexec -n 2 ./ccpic -dt.05 -da3 -s500 -ni700000 -l10
gives 4.3439922, which definitely confirms there's a timestep effect.

mpiexec -n 2 ./ccpic -dt.025 -da5 -s500 -ni700000 -l100
gives 4.4045405, which is perhaps surprising. 

Using -p-25 we get from
mpiexec -n 2 ../ccpic -dt.025 -da5 -s500 -ni700000 -l100
10.382284. Should be compared with 26/sqrt(2pi)=10.3725. Pretty good!

Conclusion

The symmetric results seem to indicate excellent agreement at 60^3 mesh
size with OML and with SCEPTIC, down to l=.1. 

Things to do next.

1. Add momentum and energy to the flux quantities monitored and displayed
by fluxdatatest.

2. Add ability to account for flux of momentum across a surface (presumably
rectangular) including the Maxwell stress.

3. These things might be incorporated into a new way of handling events
consisting of surface crossings: movement from one region to another. 
To do this we would have to keep account of what the region is that a
particle is in. Then we compare new with old before updating it. 
This seems to be already available since tallyexit will be called crossing
any boundary. We need to add the ability not to reinject if this is not
a solid boundary, and the ability to have variable oldregion (if we continue
to use insideall). 

4. Develop the ability to do more general object construction, e.g. sums
and differences of regions. This requires a way to mask insideall. Insideall
returns an integer whose bits are set for all the objects that the particle
is inside. If the object is the (inclusive) OR of two others, then the test
we want to apply to it is whether both bits are zero, in which case we are
outside. This would call for masking the others. Our current test is that
we want the particle region to be outside sphere 1 but inside 2. This works
without current problems because it is a single region.

Cases: I1 and I2 = ~(O1 or O2), O1 and O2 = ~(I1 or I2), 
       I1 and O2 = ~(O1 or I2), O1 and I2 = ~(I1 or O2).
This shows that every or can be rewritten as the negation of an and.

The values to define a region might be numerically this:
1: inside region, 0: outside region. [As currently with iregion].
A mask would say pay attention only to certain bits, not others. 
But it would have also to accommodate boolean combinations of regions.

Since we have the inside_geom function for individual objects, which is 
a faster call, probably we ought to rely on that. 

5. We need the ability to ignore the boundary of certain objects when
setting up cij. Those are objects that don't affect the poisson solution
but are there for other purposes. One way to do that would be that if
all of ABC for the object are zero, then no BC is set: so ignore in potlsect.
Did that. Seems to work correctly. 

6. Then there's an issue of volume setting. This ought to be affected only
by the particle region. That's actually true except for the tests for the
region to calculate and the volintegrate routine, which just use insideall
tests. Thus we basically need a more general insideall test that can handle
unions etc. Then it should work. 

At present compare the result of insideall with a number to tell the active
region. This is not general enough. Probably the simplest solution is to
have a logical function instead, that says: am I in this generalized region?
Then I just need a way to specify the generalized region. I don't think
it is worth the effort to devise a way to specify an arbitrary logical
operation. So instead, code possibly more than one directly and make the call
logical linregion(irg,ndims,x) where irg specifies the generalized region
numerically, but it doesn't generally do so just by its bits. For example
we could make negative irg point to a list of logical combinations, while
positive irg could be bits. 

A general way would be to have a 2-d array of numbers bool(ni,nj) such 
that the logical expression is   Prod_1^nj Sigma_1^ni inside(bool(ni,nj))c
where inside is true if we are inside object bool(ni,nj) (and negative values
of bool means true if outside). To simplify passing, one can make this
a self describing array: n1, n1*values, n2, n2*values, ... , 0

Implemented the self-describing boolean array ibool_part and gave it
a standard default. Eliminated insideall from 
pinit.f
volint.f
test in padvnc

Unfortunately there are rather a lot of places where iregion is used 
in the code. It's not so obvious how to disentangle the presumption that
iregion carries the region information. 


1 Sep 09
Installed ftnchek and made make target ftnchek. 
Started to get rid of warnings. Got most of them gone. 

2 Sep 09
Realize there are multiple types of generalizations of iregion that we need.
1. Particle region, which also defines the charge-density volumes.
2. Potential and field, solution and interpolation.
3. Additional surfaces for force and other calculations.

The particle region is defined by ibool_part. We have purged the use of 
insideall from the volume integration and particle initialization.

We need to purge iregion_part, because that usage no longer makes sense.
At least we need to get it out of being used. Currently it is _set_ in
ccpic and fieldtest, and _used_ only in padvnc. The checkcode tests its
saving, but that's not important.

In padvnc it is used to set iregion, which is passed to getfield, and 
the difference between inewregion and iregion is passed to tallyexit.
In the long run, I want to (possibly) tally all surface crossings. So
the tallyexit must be changed to use the difference between the two regions
of the start and end of step. 
We need to correct the iregion passed to getfield. It's not clear we should
pass anything. Probably getfield ought to decide its interpolation 
separately. 

Ok iregion_part is now unused.

The gradlocalregion code uses
         if(idob_sor(iregion_sor,icp0).ne.iregion)then
for testing the possibility of region crossings. Therefore, provided the
idob_sor region values are correctly adjusted to use the potential region,
it ought to work. There's no reason why getfield needs to be told the 
region. It is told the position. It can figure out the region for itself
from the position. Actually it's not so straightforward, because getfield
is given the mesh position, not the physical coordinates, and what's more
it can be given internally-based values. So really, getfield _can't_ 
currently get the region for itself. However, it could be passed the value
of insidemask and then compare it with idob_sor, which should have been
initialized with insidemask as well. Implemented insidemask and made
the changes in 3dobjects. Seems to work the same. The mask is currently
all 1s.

padvnc needs insideall for the logging information and insidemask for
the getfield information. These might be different. It's inefficient
to call both. Maybe I need a imaskregion function. Yes do it using 
the F95 intrinsic. Works. Now need to set the masking from the readgeom.
Implemented mask setting using F95 intrinsic IBCLR.

Found there's an issue with parallelpiped objects. abc are put at
the end in standard objects, which is at 8=1+1+3*nd. The objects are
described by 2*nd= center, 3 radii/lengths. But a parallelpiped needs
more lengths: an origin and 3 vectors= nd*(nd+1). If abc are at the end
then they would be in a different position. These are 3dobjects of course,
so the total is 1+12+3=16. One approach would be to require the parallelepiped
to put its data in a funny order: type origin vector1 abc vector2 vector3.
That's not totally stupid. Do it for now.

4 Sep 09

Got the code going with masking in input to getfield and getpotential. 
It works provided first two objects define the probe and the boundary, 
which is assumed in ccpic. You can then add on other objects as desired.

The sensible thing is for fluxdatainit and tallyexit to be able to cope
with other types of objects and crossings. They currently do the required
tests to see if the object is mapped or not. However, the interface left
open is the grid on the object which we are asking flux etc to be mapped
into. Currently this is programmed. 

Perhaps what is most needed is to specify what is programming API and what
is input configurable. And to separate definitively the specific aspects
from the other code.

Got xoopic (and got it going after fiddling). It is the same code base as
techx oopic, but uses the xgrafix graphics library, which restricts it to
unix-like machines. Oopic uses Qt and runs on mac and windows. It implements
most things in input files, although I think extra diagnostics can be
added on through code modifications. Its boundaries appear to be made
of individual line segments, each of which can do accumulation. There's
a load of code for parsing input and presumably setup. Boundary ends are
said to be moved to the nearest grid point. I don't know how the interpolation
is done if the lines are diagonal. 

I think the xoopic approaches are not all applicable to 3D. It's just
too cumbersome to have generalized facets and use them to construct
all objects. That was the conclusion I came to early on. I think it was right.
But I still haven't really defined the API.

7 Sep 09.

We need a way to specify the flux collection for an object in the input
file. This specification should be along the lines of the code in fluxdata.
For a sphere, we might wish to collect in angles cos\theta and \psi, with
a variable number of angles for each. In general, then we need to specify
a type of gridding and the number of bins in each of up to ndims-1 dimensions.
This would still be true if we specified the assignment in some kind of 
fourier space, such as spherical harmonics. Therefore, we ought to write
a general flux initialization code and objsect code that can handle this.
What we currently have is only rudimentary. 

The additional information we therefore need for each object is the 
flux collection type, and two integers. 

We currenly have a bit of a problem with       real obj_geom(odata,ngeomobjmax)
because the odata are ordered such that the abc is at 8, which is not enough
data prior to it for the geometric information. It might be better to 
reorder it so that this is more flexible. To do that, I need to make sure
there are no direct references to explicit values of the first index.
Ok purged all direct references to position in obj_geom. Using only
relative to the defined parameters such as otype,ocenter,oradius,oabc, ...

Permuted the order of oabc and other things. Then found a bug. It is not
in what I've just done, but it is that when an extra sphere of radius .5
is added to the objects, a change in one of the flux counts occurs.
The addition of the sphere causes one less particle count for one step
and one position. But making the radius 0.8 instead of 0.5 makes the 
differences much greater. And making it .1 gives no differences. Obviously
the counting is not working properly. This appears to be because tallyexit
chooses to count the crossing as being for the last object crossed.
This is presumably a mistake. One ought to count it for all objects crossed.
Changed tallyexit accordingly. That fixes the difference.

Implement ofluxtype ofn1 ofn2 as the object flux collection parameters.
The problem with my input file is that deciding things by ordering is
very problematic when the number of parameters on a line gets large.
Especially when one wishes to set values above others and the number
of initial values is variable. Perhaps therefore we need to rethink
readgeom routine and input format. This would be a big issue. I don't 
want to do that now, and if it needs to be done, I might write a
code to prepare the input file.

Gradually getting this done. Increase nf_posdim to 2 from 1. Fix the order
as 0 -> 1, -1 -> 1 for the position data. Then fluxdatatest still works.
(But is not yet general.) Save the dimensional structures of the
different quantities (two ints each) as well as the totals. Then we can
in principle use different grids for each quantity although at present
we can't set them to be different through the input file.

Ok. We now seem to have two dimensional accumulation grid setting through
the input file for spheres. But not yet the actual accumulation.
Rewrote the objsect code for spheres to do accumulation. Seems correct.

Try to test with different velocities. Sort of works apparently.
 time ./ccpic -s100 -v1. -ni100000  real    0m15.954s
 time ./ccpic -s100 -v1. -ni200000  real    0m30.662s
 time ./ccpic -s100 -v1. -ni400000  real    0m59.150s
Time scaling is linear in this number of particle range. (Small grid).

Got accumulation of multiple objects working and corrected the mapping
back and forth from flux objects to geom objects. Also got fluxdatatest
to work with multiple object accumulation. 

Conclusion for today
---------------------

We have 2-D accumulation of flux working. We ought to add momentum and
energy. We might want to sign the accumulation, that is, subtract or 
add according to the direction of surface crossing.

8 Sep 09

Made mf_quant equal to the fluxtype. Sensible choices might then be
1 Flux only. 4 Flux plus momentum. 5 Flux, momentum, energy. 

Found a slight problem. mf_quant needs to be set for each object, and
so needs to be an array. At present it is only a scalar. Looks doable,
but needs follow through.

10 Sep 09

This done and the flux reduction also extended to cover all quantities.
At present assuming that the grid is the same for all quantities. 
MPI seems to be working. Commit.

Edit fluxave so that it can be told a particular quantity to average
and plot. Include reporting of average flux in ccpic for objects that
accumulate it.

14 Sep 09

Implementation of maxwell stress calculations.

Having thought about the best way to implement, my idea is that calculation
is best described for a general object by a set of surface elements. 
We regard the object's surface as being approximated as a set of facets.
Each 3-D facet has
     A center position (3 reals) P.
     A normal direction and area (3 reals). A vector in the normal direction 
       with magnitude equal to the surface area: A. 

For general number of dimensions, these just become ndims+ndims.

Then the total force on the body due to Maxwell stress M is 
     Sum_{surfaces i} M_i.S_i,
where M_i is the stress at position P_i.

The nature of the approximation is left open by this datastructure, and
can be chosen appropriately. Obviously, though, the approach will work
best if the areas are approximately equal. 

For a sphere the division into cos\theta and \psi equal spacing will 
give equal areas, but it costs no extra to use the general representation.

If there are n_c cos\theta elements, the end positions are
   c_i=1-(2/N)i, (i=0,N) and the areas to be applied to element d\psi are

A_zi/d\psi = -[c_i^2-c_{i-1}^2]/2
A_yi/d\psi = (1/2)[arccos(c_i)-arccos(c_{i-1})
		-c_i\sqrt{1-c_i^2}+c_{i-1}\sqrt{1-c_{i-1}^2}]
and the optimal position to evaluate the stress for linear dependence on theta
is
	\theta = (1/2)[arccos(c_i)+arccos(c_{i+1})]
	x=r cos\theta, y=r sin\theta
[See notes]

These are referred to a plane of constant \psi, in which lie both A and x.
If there are M psi-positions, then \psi_j= \pi*(-M-1+2j)/M  , j=1,M. 
However, the area to be attributed to large \psi-angles is not given
correctly by r d\psi, because of curvature. Using a grid with cell ends at
	  \psi_j=\pi*(-M+2j)/M
we find that for A_xij and A_yij, the axes perpendicular to the polar axis,
and with \psi measured from the x-axis, the values to be used for d\psi are
cos\psi_j-cos\psi_{j-1} and sin\psi_j-sin\psi_{j-1} respectively. So

A_xij = (cos\psi_j-cos\psi_{j-1})(1/2)[arccos(c_i)-arccos(c_{i-1})
		-c_i\sqrt{1-c_i^2}+c_{i-1}\sqrt{1-c_{i-1}^2}]

A_yij = (sin\psi_j-sin\psi_{j-1})(1/2)[arccos(c_i)-arccos(c_{i-1})
		-c_i\sqrt{1-c_i^2}+c_{i-1}\sqrt{1-c_{i-1}^2}]

A_zij = -(1/2)[c_i^2-c_{i-1}^2] .d\psi

Also, the psi_cj value at which to evaluate the stress is \pi(-M-1+2j)/M.

15 Sep 09

In testing the simple field evaluator needed for the maxwell stress 
calculation, I find that there's an error in padvnc, in that the fractional
position was not always being advanced, which meant that the getfield
call did not always give the correct answer for the current position. 
Put an explicit evaluation of the fractional position into the move loop.
I don't really understand what was happening with the field evaluation
and why the errors seemed only to be in the high positions.

I think this is because partlocate is called in chargetomesh. But I see
now why there's a problem. The iteration of chargetomesh it carried out
only up to n_part. That's an error if there are empty slots. One needs
to go to higher slot numbers. That definitely needs to be fixed.
Change the iteration to up to ioc_part. That fixes it; and the update
to fraction is not needed in padvnc.

This has changed the flux. Therefore this error is significant in prior
code tests. They'll have to be redone. But anyway we now have the 
fieldatpoint code working and checked. Actually this error is not significant
in the scans I did because I used fixed particle number which does not
call this bug up.

17 Sep 09

Created stress.f that includes routines to handle the surface facet 
arrays. Code to create the arrays for a sphere has been implemented and
debugged. Tests include integrating the arrays over the surfaces to obtain
the surface area, and calculating the force on a charge/dipole configuration
in an external field. The convergence appears to be quadratic, as it should
be. However, moving the charge close to, and then outside of the sphere
leads to significant errors in the total force when the charge is close to
(within .1 of) the sphere. I guess that it is becoming the resolution issue.

18 Sept 09

Implement potentialatpoint. Tested in padvnc section. Tests in ccpicplot
are confusing because there the potential is measured outside the region.

Now we need a data structure for storing for each time step:
    maxwellforce(3)
    pressureforce(3)
and maybe other field combinations such as
    charge (integral of normal field over surface).
For each object that we are tracking.

This bears some similarities to the ff_data structure (e.g. maxsteps, obj). 
However, that data structure is rather opaque. It does not seem very 
helpful to load it up even more. Rather, it would seem sensible to 
define some linear arrays of length maxsteps (or small e.g. ndims transverse
dimension arrays).

Currently we write the whole potential phi out at the end of run. To
write it out every step would be rather crazy in terms of size. I can
imagine that we might write out some sample of phi. The maxwellforce and
pressure are more manageable. 

It seems reasonable to assume that we are going to want the field quantities
only for objects for which we are doing flux tracking. That would argue
for putting the field quantities into the ff_data or at least use the
nf_map information. Perhaps that's the compromise: use the nf_map info,
but create different data structure. This might then be
    stressdata(nsdatas,nf_obj,nf_maxsteps)
since nf_obj=5, and ndatas is in the ball park of 10, this is
an array of size 50,000 for maxsteps=1000. This is negligible. 
In the end probably easier to have separate names fieldforce, pressforce
etc in 3dcom.f.

Having made that decision it is natural to put the output into the flux
file. At present, we are just writing the whole fieldforce, pressforce,
and charge traces, regardless of used length. 

In addition we need the surfobj structure for each object being tracked.

Implemented and got to run sphere treatment only. Not yet debugged to
my satisfaction. We need some tests. 

I'm a bit confused about the flux tally type/number. Check reading codes.

19 Sep 09

The first byte of the 3dobject input (otype) is the object type 1: sphere.
Second byte is currently being used for special boundary conditions.
1:256 is used for setting phi to zero outside instead of continuity. 

The input ofluxtype is used to indicate the number of flux quantities
to be tracked, currently <=5. I don't know if this is the best use of it.

Although it is a bit inconsistent to track stresses if we aren't tracking
momentum fluxes (tally 2-4) probably it is reasonable to say that we 
track stresses if obj_geom(ofluxdata,i).ne.0. 

Got worried about the analytic testing on the 0th step. This gives
a big error unless lambda debye is very large. Yet it is a call with laddu
equal to zero. So the solution ought really to be a good vacuum solution,
since charge is zero. Checked out with older version of sorrelaxgen.f.
Same result.

I figured out that the change is in the boundary condition at the
outer sphere. Orbitinjnew.f sets it different from the natural vacuum
condition in geominit(myid). So this is actually a vacuum solution,
but with effectively a potential offset that allows the outer BC to be
satisfied.  The analytic comparison does not account for this
potential offset at infinity. To make a proper analytic comparison, I
would have to pass also the value of phi_infinity. The boundary
condition is a phi + b phi' + c =0. The values of abc are available in
obj_geom(oabc,2). A vacuum solution phi= p0/r + pi satisfies this BC if
a (p0/r+pi) + b (-p0/r^2) + c =0. Which means that the solution for pi 
must be 
     pi = -p0/r - (c-b.p0/r^2)/a 
but then p0=(phip-pi)*rc. So really
    a ((phip-pi)*rc/r +pi) - b(phip-pi)*rc/r^2 + c =0.
So 
   pi( -a rc/r + a + b rc/r^2) = -(a phi*rc/r - b phip*rc/r^2 +c)
It works.

Found that fillinlin works slightly better if we always use the field
at point to determine the gradient of the fit, rather than doing a
full gradient fit to adjacent points. Sort of makes sense.


25 Sep 09

Implemented calling of tallyexit for all boundary crossings. Only those
that are being tracked actually do anything. But now we can put a surface
in the particle region and track the momentum flux across it. Therefore
we ought to be able to compare the force components for different objects.

7 Oct 09

Getting back to this. I had updated fluxdatatest to examine the force 
integrals. It shows that for l=1, the total force is very similar at 
r=2, 4, but not the same at r=1. So there's a discrepancy not yet sorted
out. 

Run case with -l10. in which the dominant force is particles. We do
not appear to have momentum conservation. The different radii give
very different force totals. Hmm. Also, there are some Tallyexit no
intersection errors. The force at r=4 is almost twice that at r=1.  We
ought to have a delicate balancing problem with field force and
particle force. This is not working properly.

Case with (nearly) zero potential on sphere and -l200. Gives a small force
that is equal for all radii, as expected. About 3.68 for partforce. So 
momentum accounting is working when there are zero fields. 

At present, partforce is in units that are normalized momentum per sec
per rhoinf. Fieldforce is in units that are grad(\phi)^2 times
area. pressforce is in units of nT times area (I think).

Multiplying fieldforce by debyelen**2 there is a balance. But it seems
to be closer to 0.5 times the fieldforce. I need to check the coefficients. 
There is also some 9% discrepancy at the inner boundary, which needs to be
investigated. It sure looks as if 0.5 is required.

8 Oct 09

Partforce was not being reduced. Therefore for two processes, the partforce
was half of what it should have been. I think this probably explains this
factor of two discrepancy. But we still need to sort out the comparison
with sceptic.

The particle force for ccpic is  90.14934, 119.96814, 175.66409, 195.43149
for radii, 1., 2, 4, 4.9.
The particle force for sceptic is 87.89902, 196.57240 for radii, 1., 5. 
Thus, we basically have agreement in the particle forces.

The field forces are quite different for the two codes. However, this is
probably because of the different phi boundary conditions at the outer
boundary. For large debyelength like this the cutoff is outside the boundary
so the code is not really determining the force, it is being imposed by 
the BC. The fact that the totals for ccpic 224.91051, 208.83559, 206.43303
197.83185, more or less agree shows that we are pretty much conserving
momentum in the code region. But these are very different values from the
ones being given by sceptic: 540.51074, 545.98761. 

It hardly seems worth the effort of trying to sort out what the
differences are. More useful might be to impose an outer boundary
condition that corresponds to a known field (e.g. uniform) for which
the EM force is therefore known. And verify that we get the right 
field force.

To do this through the BC would require conditions whose normal component
varies over the surface. Might be tricky. Perhaps we could simply add
a uniform electric field to the field calculation. It will still satisfy
the same poisson equation. It won't then have the total potential constant
on any surface (including the inner). Probably does not matter. 

Implemented this external field. The inner surface error remains. 
The error on the inner surface with our current mesh (32^3) is about
halved at a position r=1.05, and does seem to make a finite transition
to the conserved region.

Probe potential 10. extfield.01
Field,part,press forces: -2937.02954     4.97746     0.00000 -2932.05200
================== End of Object 2 ->  3
Field,part,press forces: -2996.83130     3.71953     0.00000 -2993.11182
================== End of Object 3 ->  4
Field,part,press forces: -3087.99609     1.97120     0.00001 -3086.02490
================== End of Object 4 ->  5
Field,part,press forces: -3081.75708    -3.63166    -0.01428 -3085.40283

Probe potential 1. 
================== End of Object 1 ->  1
Field,part,press forces:  -294.28650     0.67058     0.00337  -293.61252
================== End of Object 2 ->  3
Field,part,press forces:  -300.21112     0.44164     0.00290  -299.76657
================== End of Object 3 ->  4
Field,part,press forces:  -308.82449     0.03669     0.00001  -308.78781
================== End of Object 4 ->  5
Field,part,press forces:  -307.54568     0.12403    -0.07416  -307.49582

I find that the charge is unequal in exact proportion to the fieldforce.
In other words, the main force error is arising from the integral of the
normal field over the surface, which is not giving exactly the right answer.
This is understandable, given the approximations that are made close to 
the sphere.

Thus I think we have the force calculations working, but they are showing
that positions very close to the sphere suffer from the approximations that
are involved in the field extrapolation. The charge on the inner sphere
is systematically underestimated by the extrapolation. 

Since field is accurate only to a linear approximation, and we are
using a mesh that has 16 across a radius of 5, we have a mesh spacing
of about 0.31.  The inner sphere has radius 1, so the spacing is about
1/3 of the sphere radius. It is perhaps not surprising that there are
substantial symmetric errors in the field that affect the force.
I'm not sure there's really anything one can do about it.

Fiddling with fluxdata to see what I should do about tallyexit errors.
They seem to be rounding. The tests I have don't make much sense.
Changed to a more sensible test and crossing direction calculation.


15 Oct 09

Playing with comparing ccpic with sceptic, I realize that I still
haven't really got good solutions for storing and analysing the ccpic results.
Sceptic postproc has contour plots of n, \phi. Line-outs, flux density plots
etc. ccpic has phiexamine which can do plots of \phi, but n is not well served.
Also, fluxdatatest has some plots but as yet no output useful for comparing
with other data. 

Do we need density to be output separately from the particle data? We can
certainly calculate density (instantaneously) by reading in all the particle
files. But it might be pretty cumbersome doing the accumulation. Actually
chargetomesh seems just to accumulate, not to initialize. Therefore we
just need to call it for as many particle files as exist. However, the particle
data files do not contain the mesh structure.

Easier route just reproduce the phiexamine structure as
denexamine. Including writing out the density. This works. But there's
a serious problem in that the noise level of the density is very high,
at least on 32x32x32 with default particles. The noise level is of
order 1. This is, of course, no different from what one might observe
with graphics during the run.  The files for density (and phi) are
about 15 times smaller than one file of particle data (for 52k
initialized particles). So it might be worth considering outputing multiple
steps. One might also do time averaging. Implemented averaging and output
the decaying average with 100steps default. Even so with the standard 
settings the density plot is pretty noisy, and with 2 processors, added
steps and 200k particles there's still a considerable noise level.

16 Oct 09

I've plotted the density as a function of r for individual mesh
points. It would reduce the scatter if the 2-D case were gathered together
into bins that correspond to theta angles.

20 Oct 09
Completed additions to phiexamine, denexamine, which bin things together
and then print them out. 

Created a general purpose plotting routine that can read the print out from
ccpic tools and from the sceptic tools. Compared the -p-10, -l1. cases.
Excellent agreement with potential and density right out to the edge.
See in src/plotting/.

Conclusion.
__________

I declare success with the comparisons between ccpic and sceptic in
moderate debyelength cases. They have excellent agreement on flux,
potential, and density for v=0 cases. Forces for flowing cases need
more study because of the finite-domain effects. Also for -l.1 there
is a significant discrepancy at the boundary. The potential is too
small in ccpic and the density is rapidly trending up towards 1. It
looks as if there's a problem in the boundary condition. However, it
is hard to be sure because the discrepancies in average values are
several times smaller than the instantaneous fluctuation levels.


Next Steps   30 Oct 09
---------- 

I think we need to move away from the spherical region and use cartesian
region out to the boundary. We need to work on such facilities as periodic
boundary conditions, or at any rate rectangular BCs at the computational edge.


-----
Did some housekeeping to clean some testing code out to the subdirectory.
Also rename fluxdatatest to fluxexamine. 


11 Nov 09

Renamed bbdyroutine.f to bdyroutine.f. Cleaned it up so that it is easier
to understand the boundary setting routine. 

'Free' rectangular boundary conditions. Might consist of putting the
logarithmic derivative equal to 1 or 2 or something. But on a
rectangle the logarithmic derivative is not so obvious. If r.grad(u)/u
is the radial logarithmic derivative D, then the component in a
particular cartesian direction x is grad(u).x = D (r.x) u/r^2, so
presumably we should set grad(u).x accordingly. Notice the 1/r^2
dependence involves the orthogonal coordinate values. Consequently, one
needs ways within the bdy routine of knowing what the mesh positions are,
or else some other more direct way of passing the setting information. 

Implemented that in fieldtest and bdyroutine bdysetfree. But needs a
different geomtest file: geomtest2.

Also geomtest3 has two separate spheres.

24 Nov

We need now to deal with the outer boundary for particles, when there
is no explicit bounding object. Particles contribute their weight to
the second row/column until they reach the exact edge node
position. Consequently, we ought to consider the particle region to
extend all the way to the edge nodes, if we wish to get the second row
density correct. The contributions to the edge nodes is half what it
ought to be because there are no particles outside. However, the edge
node density is never used, and indeed the volumes of the edge nodes
are not currently set. There will never be an overflow of index for
charge assignment beyond the edge, provided that we never go past the
edge nodes.

In summary: the default particle boundary is the edge nodes. 

The routine insideall is used by padvnc. This approach needs to be 
extended to include the default outer boundary. Currently the mesh is
set using xmstart/end, but there are no switches to change those. They are
+-5. Also rs is in the common, and used for a few things. We need to change
to using the real mesh size, which is set by meshconstruct. 

Relevant routines.  

	 readgeom reads in objects

	 geominit sets rc from first, rs and rsmesh from the second object
	 assumed to be a sphere, and overrides some BC, from orbitinjnew.f.
	 This will be changed when we are doing away with outer sphere. 

	 meshconstruct accepts xmstart(3) xmend(3). 

Implemented command line switches to change xmstart/end. A problem emerges
that stored3geom is not changed, even though the mesh has changed. Because
of that ccpic thinks the volumes are what they used to be, and does not
recalculate. I think we need to store the mesh data in the stored file. 
Implemented storing and checking of ixnp. Fixed.

Crunch of geominit prevented by softening the oabcset error. 
Then pinit hangs. So we can fix this. We need to fix linregion and
then fill up between mesh limits. Actually I don't think there's any
need to edit linregion. I find that the issue is that rs is apparently 
zero. Anyway, dispense with using it by making pinit fill the whole mesh
region with particles in so far as linregion is true.

Now we get as far as stepping and find Relaunch NaNs. 
Found that problem due to rs being reset to zero, and fixed.

It seems as if the best approach to keeping particles within the mesh is to
use the partlocate call. This is tricky because at present partlocate
is called by chargetomesh. But this separation just makes the code harder
to understand. The best thing is to get all the partlocates into padvnc
and ensure after every move, we do the partlocate so the position is in
fact known. To remove partlocate from chargetomesh, we perhaps need
to call it for all the particles when they are initialized. We do, but
somehow this is still not working.

30 Nov 09
Was not setting the pointer iinc properly. Fixed, but now the calculation
of the pointer to position (iu) in partlocate appears to be redundant.
It is not used in padvnc, only in chargetomesh, where it had to be 
done separately. So purge out of partlocate the calculation of the 
pointer. Simplifies and reduces argument count.

Now we need to implement some convenient way to detect when partlocate
overflows the interp. Perhaps a specific large iregion. No. Add a logical
argument. Then test this. Implemented.

1 Dec 09

Putting Mesh information into the geometry file.

It becomes clear that we ought to put the mesh information together with
the object geometry information. Presumably in the same input file.
A general way to specify the mesh information would be to provide for 
each dimension two flexible length arrays:
imeshstep: 1, ms2, ms3, ..., msN
xmeshpos:  xm1,xm2,xm3, ..., xmN
which determine the mesh number corresponding to mesh position.
Thus imeshstep=1,32; xmeshpos=-5.,5. corresponds to a uniform 31-step 
mesh 1-32 over domain -5. to 5.
imeshstep=1,12,20,32; xmeshpos=-5.,-1.,1.,5. is mesh with 3 domains 
1-12 covers -5. to -1.; 12-20 covers -1. to 1.; 20-32 covers 1. to 5.
An imeshstep value of 0 indicates no more array. 

To convert this to the meshcom ixnp and xn values requires that the 
dimensions be known in the correct order (x,y,z,...) so one has to set 
them all (perhaps to defaults) and then do the conversion. 

Implemented structure and default initialization for imeshstep and xmeshpos.
Implemented new meshcontruct to use that default. Gives same answer.

Format in the geometry file will be for dimensions 1,2,3:

91/2/3, ms1,ms2,...,msN,0,xm1,...,xmN,0

Seems to work.

Now trying to rationalize things, we find a logical problem. 
iuds is now set by meshconstruct. That has to be done after we 
have determined myid. But the initialization of sormpi discovers myid,
and it needs to be passed the value of iuds. 

I think this requires me to get rid of the early initialization, which 
was anyway very artificial. Instead I can use a routine getmyid to
get it. This does not seem to need any changes to sormpi. Yes it works
nicely and easily. This is a much better approach. Also got rid of
xir the point assumed to be in the region. Now just use linregion.

Don't seem to have gotten to the bottom of the difference with or
without stored geom. There is a call to ran1 that ought to reset it.
Thus it's not clear that the difference arises from the random
numbers.  However there did seem to be a difference in pinit: 100776
when set, vs ntries= 100414 when read back. So if the random number
generator is not this issue what is? 

Ahh! It WAS the random number generator, because pinit was erroneously
using the old rand instead of ran1. I use rand() _only_ in volintegrate
because of the big cost there of number generation. So now fixed. 
We get the same answer whether or not the stored3 read is successful.

Today
_____
We implemented mesh specification in the geometry file.
Rationalized some of ccpic, notably the mpi initialization. 
Fixed a bug in the pinit call and stored geometry differences. 

Discovered a bug in slicegweb to do with non-equal side domains. Actually
it's a feature. Hidweb is set not to rescale until done explicitly.

2 Dec 09

Now we need sensible reinjection for the whole rectangular domain.
Issues include
1. How to account for any non-zero potential at the domain edge?
2. Are there many interesting situations where periodic reinjection
   would be useful?
3. How to deal with situations where some part of the boundary is outside
   the particle region. 

One thought about 1. is that one might use reinjection at infinity followed
by integration in an approximated spherically symmetric potential. The same
approach as in orbitinject. One would have to use an impact parameter range
that extends to the boundary of the cuboid region. This is substantially 
larger than the largest sphere that fits within the region. Radius is larger
by sqrt(3), so impact parameter area is larger by 3. Consequently there
would be substantial (factor 3) inefficiency in the process. It might also
be tricky to determine whether the orbit intersects the sphere. 

Probably the use of the Green's function solution for this purpose is
overkill. Certainly it will not arise naturally for the actual boundary
conditions of a cube. Other issues arise if the domain is a very elongated
cuboid. Then the spherical symmetry is a bad approximation (perhaps). But 
in any case the injection inefficiency will rapidly increase. 

Overall, it seems unlikely that an orbitinjection approximation will have
sufficient accuracy to warrant the trouble. A straight approximation of
cartesian reinjection of the infinite-distance distribution function ought
to be pretty easy, but will not account for external acceleration. 

Options for ad hoc adjustment of the injection to correct for external
acceleration include 
1. Adding normal energy. (Enhanced normal inward velocity).
2. Adding total energy. (Keeping the velocity direction fixed.) 
3. Some other directional assumption.

Should one change the distribution across the boundary? If one were
in a quasineutral regime, then perhaps the density ought to be weighted
by the Boltzmann factor. One way to do that would be to roll the dice
and reject the particle if above exp(\phi), where phi is the local
reinjection potential. This would appropriately contour the weight. 
However, it would not be correct for a long-Debye-length situation. 

 Periodic Reinjection. Even if periodic reinjection were used for
particles escaping the domain, one would still have to deal with particles
lost to the objects, and their reinjection. Therefore periodic reinjection
does not actually solve the problems of reinjection. It could be an
option for some (or all) of the external boundary surfaces. It could be used
whether or not the potential boundary conditions were periodic. 

The first thing to do is to implement a shifted maxwellian calculation.
If 
   f(v) = C exp[-m( v - v_d)^2/2T]
then the total number with positive v-direction is
   N_+ = C \int_0^\infty exp[-m( v - v_d)^2/2T] dv
       = C \int_{-v_d/\sqrt{2T/m}}^\infty exp[-t^2] dt \sqrt{2T/m} 
       = C \sqrt{\pi}/2 \sqrt{2T/m} erfc(-v_d/\sqrt{2T/m})

Since erfc(0)=1, erfc(-\in+fty)=2, the normalization is such that \int f dv
= 1 if C \sqrt(\pi}/2 \sqrt{2T/m} = 1/2.

The flux density above velocity v_0 is 
    F(v_0)  =  C \int_v_0^\infty exp[-m( v - v_d)^2/2T] v dv
       =  C \int_{t_0-t_d}^\infty exp[-t^2] (t+t_d) dt {2T/m} 
(putting\ t=(v-v_d)/sqrt{2T/m})
       =  C2T/m [-exp(-t^2)/2 - t_d \sqrt{\pi}/2 erfc(-t) ]_{t_0-t_d}^\infty
       =  C T/m [exp(-(t_0-t_d)^2) + t_d \sqrt{\pi} erfc(t_0-t_d)]
       = \sqrt{T/2m} [exp(-(t_0-t_d^2))/\sqrt{\pi}  +  t_d erfc(t_0-t_d)] 

Approach: 

Decide the face to be injected at, by random choice weighted by F x Area. 
Decide the position on face by random 2D rectangular.
Decide the tangential velocities using gasdev (drawing from maxwellian).
Decide the normal velocity by drawing from the above distribution:
       how do we do that distribution draw?

We need to be able to invert F(t_0). 
That's not obviously feasible analytically.
Seems as if we need to form a numerical table of F(t_0) and interpolate
the inverse lookups. This would require six tables: one for each surface.
But at least they only have to be one-dimensional. 

7 Dec 09

Created integrator code. Programmed a fairly smart integrator
subroutine cumprob. 

8 Dec 09

Programmed reinjection code.
Programmed testing/creintest testing code.
I find that the histogram reinjection distribution shows up on the 
testing distributions. Thoughts about fixing that include the idea
of some higher-order interpolation. However that is not straightforward
at the edges, where it most matters, because the inverse cummulative
probability curve has infinite slope there, so how does one fit that? 
It's not clear that a parabolic interpolation will work. If I add a 
further node outside the real range, which has a value much (by some
chosen factor) beyond the bottom. This might work. On the other hand it
probably won't be faster than simply using a finer mesh for the inverse
cumulative curve. Using 1000 arrays seems to give a pretty good result.

9 Dec 09

Constructed (finally) a four point cubic interpolation routine. Checked
numerically. However, when used in creinject, it makes things worse. There
are spikes near the last but one point. Don't know why. Perhaps it means
that the interpolation is non-monotonic (or nearly so). This is not 
completely crazy, since a parabolic interpolation of a sharp corner from
nearly flat to nearly vertical will produce overshoot. This may be
the reason. At any rate it appears to confirm that it is very tricky to
improve the inverse-cumulative approach by higher order interpolation. 
I think it comes down to needing either to use a decently high number
of nodes, or not using the inverse cumulative approach. The old finvtfunc
approach was not bad. Settled for 1000 array for now. Linear interpolation.

10 Dec 09

Finished creintest.f to include testing of position. Seems correct.
Now we need the cartesian versions/equivalent of nreincalc, geominit,
rhoinfcalc.

Implemented nreincalc and rhoinfcalc using 
flux = ninfty sqrt(2Ti/pi)[A_1+A_2
       	      +A_3{exp(-td**2)+sqrt(pi)/2 t_d[erfc(-t_d)-erfc(t_d)]}]
and including a phirein correction factor of
         cfactor=smaxflux(vd/sqrt(2.*Ti),chi)/smaxflux(vd/sqrt(2.*Ti),0.)

(Not yet particle energy correction.)

geominit is specific boundary setting for this geometry. Null for now.
It compiles.

It would be nice to have geometry files ccpicgeom.dat that were automatically
invoked for the different geometry assumptions. Might be possible to 
replace ccpicgeom within ccpic with a value that depends on the REINJECT
case under consideration. Better to build a link into the make structure
and change it according to whatever reinject we are using. Did that and
cvs added geomsphere.dat and geomcubic.dat. Cartesian reinjection is
actually not yet working. We aren't reinjecting anything. 

Made some progress on getting things to run. But not to the bottom of it
yet. denexamine and phiexamine don't run quite right.

11 Dec 09

Ok the main problem seems to be that the sign of the normal velocity
is wrong and so particles leave immediately. Fixing this, there is still
a small problem with sign of particles because the inverse cumulative
probability extends slightly across zero, presumably because of the
integration and interpolation. Consequently there are a few wrong signs
still. I suppose we could fix this artificially. Did that.

Now things run with sensible particle numbers but there are some very 
strange peaks in the density that make no sense. And seem to be in straight
diagonal lines for some number of cells. This was because I used idum as
the argument for ran1. It needs to be >=0 for standard call. And idum
was uninitialized.

Finally got some runs that look plausible, although currently with
potential set to zero at the boundary (the current default). Actually
no. The potential is set to zero on two dimensions and something else
in the third.

Cartesian boundary flux tests. 

32^2 grid ./ccpic -ni200000 -dt.025 -da5. -s500 we get rhoinf 212.67125
Flux density*r^2, normalized to rhoinf   3.9655340. This is to be compared
with 3.997 with sceptic or with 60^2 grid. Broadly we are getting the 
right answer. Close to OML (4.388 for -p-10).

With -l.3 we get: 2.8120570 c.f. 2.77 with sceptic etc. All pretty promising.
I see that the printout from the run is different from what fluxexamine
prints out 2.8006816, but close. Not quite sure why. 

With -l5. I don't expect a good result, because of the BCs. Get 4.795. 4.777.
C.f. 4.395 sceptic. This is 10% in error. Not a great result. 


Summary
-------
Code seems to be working with outer injection boundary at the mesh edge.
Gives promising agreement with prior runs at -p-10, even with relatively
small (32^2) mesh (and inappropriate boundary conditions). 



14 Dec 09

Implement boundary setting of slope to -(1.+r/\lambda_s) with lambda_s
currently set as the linearized value. This works reasonably well to
maintain the phi contours circular at intermediate values of debyelen,
and presumably is close to the right answer for large debyelen, although
arguably it ought to be closer to -2, not -1 in the far distance. 
At small debyelen, the value of the slope doesn't much matter.

Then ./ccpic -ni200000 -dt.025 -da5. -s500 gives
3.9668663. Essentially no change. -l5: 5.2031398 yikes! Too large by
big factor (rhoinf=135.45, 8818). Try logarithmic slope of -1.: 5.3926058
(rhoinf=122.93, 8330) . Also very large. Repeat old bdy run: 4.7955675 (this
forces phi to nearly zero at the boundary rhoinf=161.79, 9714).

This is rather worrying. It looks as if one gets a very bad result if
the boundary potential is non-zero. I think this is because I don't
yet correct the energy of the reinjected particle by phirein (or some
other local potential correction). Scale velocity by
(v^2-2.averein)/v^2. Initially I used phirein and got problems with
overrunning the diagv. This is because phirein is not equal to the
averein of the prior step in the middle of the particle advance.

Now with -l5 get 3.6797631, rhoinf 149, 6897. Too small by a comparable
amount. -l1 3.8620880 214.66699 10418.302
-l.3 2.8107293 219.31303 7746.276

What I think this experience shows is that the cartesian geometry is
not very good for treating an isolated spherical object. Not because
of the cell shape but because there are no convenient approximations
for the boundary condition that allow one to take credit for the 
isolation of the object, and not have to go as far out with the domain. 

If the domain were part of an array, so that periodic boundary conditions
apply, then this weakness is turned into a strength. Probably periodic
conditions ought to be investigated. 

To get into a physics problem soon, we could address the wake issue. This
would also lead to exercising different meshes and perhaps even differently
spaced meshes.

For now, commit. Getting back to sceptic machine we don't get the correct
answer. This proves not to be a function of the cvs version because getting
it to ihhutch gives ok result. I notice that although there's a gfortran
on sceptic.psfc mpif77 appears to be using g77 instead. This might
conceivably be the cause of the major problem. It is that face of the
grid is being significantly depleted of density. Perhaps there's a problem
with reinjection, e.g. that no reinjection is occurring there. In any
case it is probably worth pursuing the problem on sceptic.psfc to figure
out the portability of the program. 

Prove that it really is the mpif77 version by using the -f77=gfortran 
switch. That gives correct answers on sceptic.psfc, although not _exactly_
the same as on ihhutch. At least the major error has gone away. The version
of gfortran is not the same. It seems there are very small differences. 

It is by the way noticeable that the g77 version runs very substantially
faster on sceptic.psfc. Maybe as much as a factor of 2! That's pretty 
significant. 

The depletion of the g77 version is at the -5 end of dimension 3. It appears
gradually with steps, which suggests that perhaps it is associated with 
reinjection; but it could be other things. Since we don't have obvious 
code errors, it is not completely obvious how to proceed. There is no
evidence that creintest gives any difference. 

A force shows up in the faulty version. And eventually a significant
flux asymmetry. There's definitely a particle flux towards negative z,
which is consistent with a reinjection deficit there.

The faulty version shows substantial n_part degradation after 100 steps:
0096  53 3.758| 0097  54 3.228| 0098  53 3.565| 0099  53 3.767| 0100  54 4.023| 
nrein,n_part,ioc_part,rhoinf,dt= 2394  76849  99993    94.749     0.100
compared with
0096  53 3.882| 0097  53 4.035| 0098  53 3.875| 0099  53 4.144| 0100  53 3.888| 
nrein,n_part,ioc_part,rhoinf,dt= 2394  91379  99984    97.415     0.100

Thus there really does seem to be a loss of particles. Got g77 installed
on tp400 and then I can reproduce the g77 problems there (and its speed!)

16 Dec 09

The reinjection diagnostics do not show any asymmetry problem in cos\theta.
Nor are any warnings given about reinjections outside of region. Therefore
there's a bit of a puzzle as to where to look for the error. 

Perhaps we need a way to examine the particle data and plot
distribution functions etc. This would involve reading back the
partdata and then binning it by velocity, for some selection of
cells. One ought to allow the possibility of reading more than one
file worth of data. But it is not straightforward to provide
sufficient storage for the actual data of many particle files. Each is
potentially quite a lot of megabytes. Also the file reading apparatus
might break unless we shuffle stuff. It might be better to reread the
files if a new selection were required. That would be reasonably quick
if the files were in disk cache memory. So the process would be
1. Read a file .00N 2. Bin its particle data. 3. Repeat till all done.
This could be done on a selective basis (perhaps). 

Created partexamine code to do this. It shows that in the depleted region
at the bottom z end, the distribution function is (approximately) 
one-sided. Also, density goes to zero at the edge, not half, because
the particle bins can be chosen finer than the charge mesh. And starts to
drop at about -4 (which is about 3 cells from boundary) after 5 steps.
This effect can be seen propagating inward as one increases the number of steps.
If we set the number of steps to zero, there is no depletion. 
Setting dt to a small number we can see more clearly the depletion region.
It is the bottom _half_ of the bottom cell. 

Putting a test hack padvnc call outside the main loop and using -s0,
I find that it is definitely padvnc that is causing the depletion.
It seems that x_part(3) is corrupted on entry to partlocate.
Also xpart(6) is corrupted and seems to be the source of the corruption.
Yes this is coming from the getfield, and is corruption of the value.

I think the problem is in field interpolation at the boundary. We are
not (it seems) setting the boundary pointers in such a way as to
prevent trying to get potential from past the end of the mesh for
interpolation.  Actually I can now see the problem from within -gt
tests.  I think this problem would be fixed if the boundary points
(which all have pointers to data) all returned a region that was
unique. getfield would then never allow itself to use those boundary
points as the centers of extrapolation. As a result, it won't grab
data beyond the boundary.

Implemented this different boundary value as -1. Also fixed the
text3graphs to cope. Then found a logic bug in the getfield code that
did not treat the whole thing appropriately. Found a bug in the
solu3plot routine that overran the mesh domain at certain angles and
hence gave nans returned for the field. Have not made getfield
completely bullet proof against incorrect fractions in call, because I
was nervous about slowing it down. But now things ought to work.
Ok. No obvious evidence now that we are broken.

There's an inconsistency in rhoinf, n_part, and nrein. With multiple
processors, we initialize 100000/numprocs particles by default. Which
is probably a bad choice, but then also we seem to be injecting more
particles. The defaults are as follows:

17 Dec 09

c Fixed number of particles rather than fixed injections.
      ninjcomp=0
      n_part=0
c Default to constant rhoinf not n_part.
      rhoinf=100.
Then in initialization we do
c      write(*,*)'Doing nreincalc',n_part,rhoinf,dt
      if(n_part.ne.0)rhoinf=0.
c Set ninjcomp if we are using rhoinf
c This does not work until after we've set mesh in cartesian.
      if(rhoinf.ne.0)call nreincalc(dt)
Nreincalc does:
c Correct approximately for edge potential depression (OML).
      chi=min(-phirein/Ti,0.5)
      cfactor=smaxflux(vd/sqrt(2.*Ti),chi)/smaxflux(vd/sqrt(2.*Ti),0.)
      ninjcomp=nint(rhoinf*dtin*cfactor*flux)
      nrein=ninjcomp
      if(ninjcomp.le.0)ninjcomp=1
      n_part=rhoinf*volume/numprocs
where flux is normalized flux-density times area. 
Then we call pinit which does:
      n_part initializations (per proc) and then
c Initialize rhoinf:
      if(rhoinf.eq.0.)rhoinf=numprocs*n_part/(4.*pi*rs**3/3.)
which should be changed, for cartesian volume, incidentally. 
When nrein is reduced, it is **summed**. 
rhoinfcalc is called each particle advance cycle. nreincalc is not.
rhoinfcalc does:
      if(nrein.ne.0)then
c Calculate rhoinf from nrein if there are enough.
c Correct approximately for edge potential depression (OML).
         chi=min(-phirein/Ti,0.5)
         cfactor=smaxflux(vd/sqrt(2.*Ti),chi)
     $        /smaxflux(vd/sqrt(2.*Ti),0.)
         rhoinf=(nrein/(dtin*cfactor*flux))
      else
         if(rhoinf.lt.1.e-4)then
c Approximate initialization
            rhoinf=numprocs*n_part/(volume)
            write(*,*)'Rhoinf in rhoinfcalc approximated as',rhoinf
     $           ,numprocs,n_part
         endif

Thus nrein during iteration refers to the total reinjections, and
rhoinf to the total density including all processors, but ninjcomp
refers to one processor's injections, as (of course) does n_part.
I want the default injections to be rhoinf=100*numprocs really. 
But in any case, the initializations should be such that things are
consistent. ninjcomp is only ever set in nreincalc, i.e. only ever
during initialization.

Need to make a decision about how defaults are command lines work with
different processor numbers. I want adding processors to add particles,
which means that rhoinf goes up. Thus if I specify rhoinf on command line
or default the actual rhoinf is not this value it is this value times
numprocs. This is correctly handled within rhoinf at present if we 
change the meaning of rhoinf from being per processor to total when
we call nreincalc. Hence we change it to 
      ninjcomp=nint(rhoinf*dtin*cfactor*flux)  ; per processor
      nrein=ninjcomp*numprocs		       ; total
      if(ninjcomp.le.0)ninjcomp=1
      n_part=rhoinf*volume		       ; per processor
      rhoinf=rhoinf*numprocs		       ; total
This appears to work consistently. But ought also to be changed
in orbitinject. Did that.


Discovered a problem with testing/fieldtest. Points on mesh edge are
having their phi values changed, apparently to match the derivative
across the object mesh boundary. This presumably is not really needed.
Actually this happens also in the orbitinj version of ccpic. Although
you need to look harder to see it. Basically this is a problem with 
the bdyset routine, which ought not to do gradient setting in these
situations. 

Timing. 

G77       ./ccpic -s200 real    0m31.220s
Gfortran  ./ccpic -s200 real    1m10.779s

This is a really quite amazing discrepancy. Compare with 

./ccpic.gfortran -s50 -ni500 (negligible number of particles) 0m16.886s
 time ./ccpic.g77 -s50 -ni500  0m5.003s

 time ./ccpic.gfortran -s50 -ni500000 0m50.750s
 time ./ccpic.g77 -s50 -ni500000  0m45.196s
Hardly any discrepancy here.

Conclusion: Gfortran is taking 3x longer for the poisson solve, whereas
the particle mover is pretty similar for both compilers. (These are all
on concentric spheres.) The number of iterations is pretty similar.

Profiling gfortran shows time is dominantly in sorelaxgen mditerate,
bdyslopescreen, r2indi. There are 20 Million calls to bdyslopescreen.
Seems probably too much. For g77 bdyslopescreen and r2indi are also
the major players (though not quite so dominant. 19M calls. 

Is this reasonable? bdyset is called for each sor iteration (I think),
average 60. For each step 50. For all boundary points 32x32x6faces.
Total roughly: 18M. Yes this is a reasonable number. Seems as if this
boundary setting is not negligible, as I thought it would be. 
For 32^3 mesh the number of boundary points is only roughly 1/5th of total
number of points.

First thing. I don't think we should be calling the bdyset routine 
every step, only every _other_ step for the red-black routine. 
Second, one might argue that for the PIC the boundary routine ought
to be called only each particle step. 
Third, this is really scary because bdyset does not get shared out
between all the processes. So parallelism won't help. Scaling will
be terrible. 

I notice that the total number of seconds isn't adding to the elapsed
time. And actually the amount of time (about 2 seconds) isn't much
different. Maybe I'm not really profiling where the real time is being
spent. If that's so, then I'm probably not really getting to the bottom
of what is taking the time. I think I ought to be getting library routines
that allow profiling but perhaps I'm not.

On sceptic results are similar except the seconds count is 7 not 2.
Still the calls are more or less in the same place. Same with g77 and
with gfortran. It might be nice if one could compile without MPI, 
which might be some of the problem. 

Installed valgrind. The picture it draws is rather similar, but it detects
that there's a significant amount of time spent in the exp function.

There's no question that g77 is way faster -- up to a factor of 3 --
than gfortran, no matter what optimizations I use. Both are 64
bit. They use the same libraries except for libgfortran vs libg2c.
A real puzzle.

Profiling does not track libc libm without the profiling libs.
Installed them libc_p etc. But then can't get a program that does
not crash. This is a known bug:
https://bugs.launchpad.net/ubuntu/+source/glibc/+bug/193487

In general the flags required are  (-g) -pg -static-libgcc -lc_p
Installed gcc-4.1 which is said to work with these. But that does
not seem to propagate to gfortran. So I haven't really made progress.

Found a small time saving in sorrelaxgen where the parity change is done.
Saves about 10% of time in this routine, but not much overall. 

21 Dec 09

Made a unique version of accis and added to the repository as a subdirectory.

Found that even g77 version runs slower on cmodws48 etc. 
These machines have 
cache size      : 2048 KB
whereas both sceptic and ihhutch have
cache size      : 6144 KB
This is probably the reason. Cache misses may be the secret to understanding
the performance.

Tried reducing Li in ccpic. No significant difference. Reduce partcom
n_partmax to 100000: no significant difference. Well I haven't proved
that it is cache misses.

Ran some cases to see if I can get wake structures similar to those
in sceptic. With +-10 mesh extent, and -l3, -t.1, -v1., p-2, a trailing peak
can be clearly seen (but trough seems past the end. 
Generally the results seem qualitatively consistent with what I saw
with sceptic. 

Ran some rectangle cases. Also don't show negative dip in wake.
Ran an asymmetric case -5,+15. It shows a tiny dip in the wake. 
All this is consistent with sceptic. Now in 3-d.

23 Dec 09

Found problem with cumprob. There are cases when the integral is zero.
We need ways to cope with those, and also with cases where the integral
is too small to be significant, but still appears non-zero. Implemented.

30 Dec 09

Ran a number of cases designed for wake studies on sceptic.psfc.
These show quite oscillatory wakes (unlike the sceptic case). Using 
-l10 and -l20 one gets quite similar scaling with domain size up to 
400 long (50 wide). However, it is very clear that the size of the first
potential peak never gets much larger than .15, no matter how strong the
perturbation (charge \propto \phi x r scaled to lamda_debye). It seems 
as if I can actually reproduce the oscillatory wakes of the linearized
cases, but only with correct amplitude if that amplitude is less than
0.1(Te). It would be nice to do some really quantitative comparisons. 

1 Jan 2010

Investigating partial edge error with zero-derivative boundary condition.
I find this emerges only with multiple processes, but then with standard
cubic boundary conditions. Must be a bug in the communications logic. 
I believe that the edges are not communicated on principle. Why is that
a problem? 

The error seems to be arising in the final boundary setting after the
allgather. It appears to go away if the final boundary setting is
done twice. I think the logic of this is that, after the allgather,
boundary conditions are not set, so boundaries don't satisfy the condition.
Then calling bdyset implements the setting. However, at edges/corners, the
setting might be from an incorrect boundary value along a face to the edge.
In that case the edge value is incorrect after one setting. If a second
setting is done, then the extrapolation is from a value that is correct.
So the whole is then done properly. In general, I think this shows that
when a corner is set prior to the face value that it is extrapolated from,
it is incorrect. I believe this incorrect setting probably does not affect
things in normal operation, because the edge values ought not to be used.
But I'm not sure about that. In any case, we ought to fix the error. 
I've assumed that we can set an edge value from either of its faces.
That's not so. In fact sometimes we can't correctly set it from either,
because they have not themselves yet been set. This problem would not
exist if we could start from the middle of faces instead of the edges.
Maybe, but maybe not, I think we'd need to start at position 2s. 
Do the non-edge faces first, then do the edge faces. It doesn't look 
easy. 

Actually it is not very difficult to implement a more correct
algorithm, based on extrapolating from the nearest body (not face)
point. (Still iterating in the natural order).  It appears to be just
as fast and direct although recoding was necessary.

The run of the v10 cases was done with -t.01. I confused this with timestep
and did comparable runs with -t.1. These are much higher temperatures.
They'll be interesting. The old runs with -dt.1 are fine as far as
timestep is concerned. We've now got two temperatures.

2 Jan 2010

Working on padvnc to incorporate collisions in a compact way.
First clean out the testing code. 
Now reorganize the logic to make it more readable and comprehensible.
Localize the reinjection in one place (which requires logic adjustment).
This is all working. 

Now there appears to be a bug in that dtaccel=0.5(dt+dtprec). This is not
correct. It ought to be dtaccel=0.5(dtpos+dtprec). On reinjection, dtpos
is put to a random fraction of dtpos; and dtprec is put to zero. This means
that we are treating the prior step as of zero length, so that the position
and velocity are simultaneous. For the next step, we therefore want to
advance the velocity by half of the timestep (with nothing for the prior
timestep). But dtpos is the timestep, not dt. Correct this small error.

Then we can use dtpos as the remaining timestep in a subcycling associated
with collisions. 

Implemented both collisions and subcycling.

24 May 10
Got a problem with NANs in case with very large number of particles.
The Field corruption test was triggered. 
This turned out to be caused by initialization to a position exactly
on the mesh boundary, where the field was obtained incorrectly. 
Fixed partlocate to declare NAN position to be out of mesh.
Fixed pinit to ensure exactly on boundary is rejected.
Also fixed interp to reject NANs. 

28 May 10

Thinking about names. One idea was Cartesian Orthogonal Particles and
Thermals in Cell: COPTIC. It would be better if the O could refer to
the object boundary representation. (Since sceptic has orthogonal
coordinates.) Ideas: Oblique (referring to the boundary). I can't
think of anything better

Cartesian[-cell] Oblique[-boundary] Particles and Thermals In Cell: COPTIC 

Changed the makefile and the main filename.
Added to the CVS modules file the alias coptic CCPIC.
Committed. Now one does a cvs checkout coptic and gets the file with
the program name changed to coptic. There are some residual files with
ccpic as part of their name. Don't change them because it is too much
trouble.

Implemented a make feature that saves in REINJECT.f a single fortran
line that sets a character variable equal to the REINJECT configuration.
Then added a feature into coptic that checks if the particle region 
boolean has any objects that it is _inside_. If so, this is a 'bounded'
region. (Even if there is an unbounded region outside as well as the
bounded region inside.) If the particle region is 'bounded' and the 
injection scheme starts 'cart' (cartreinject.o), then this is an incompatible
scheme, and the code stops with an error message on initialization. 
This will probably be tripped only if the objectfile is explicitly 
specified and incompatible.

30 May 2010
Implementing more satisfactory potential BC. We want the potential to
be constant along a direction d which is a vector radial in x,y and
has a z-length v_d times the radial length. Implement this as a
boundary condition that set the boundary value to satisfy this
condition. One is probably safest deriving the tangential derivatives
from the values on the active mesh, one in from the boundary. The
normal derivative from the boundary point and its neighbor in the
active mesh. Should the tangential derivatives be centered? If so one
requires to go forward and backward from the point in the tangential
direction. This will work ok except for the edges. (Faces are ok.) At
the edges, one could just use an uncentered difference, but it might
be better to extrapolate from the 1,1 point diagonally in from the
edge point. If one does that, then an uncentered difference might not
be required.

We first analyse the current slopeD routine:
ccSet the cumulative registers
      r2=0.
      fac=0.
      ipd=ipoint
      do n=1,ndims
c BC is du/dr=D u/r     in the form   (ub-u0)=  D*(ub+u0)*f/(1-f)
c where f = Sum_j[(xb_j+x0_j)dx_j]/(2*rm^2), dx=xb-x0
c Thus ub=u0(1-f-D.f)/(1-f+D.f)
c Here we are using radii from position (0,0,..)
         x=xn(ixnp(n)+1+indi(n))
         r2=r2+x*x
         if(indi(n).eq.0)then
c On lower boundary face
            dx=xn(ixnp(n)+1)-xn(ixnp(n)+2)
cc ixnp(n)+1 and ixnp(n)+2 are the point and its adjacent.
            ipd=ipd+iLs(n)
cc ipd is the index of the point adjacent in the n direction.
            fac=fac+x*dx
cc accumulate dx*x, the projection of the step along the r-direction.
            if(n.eq.1)then
c The exception in step. Do not change!
               inc=iused(1)-1
cc This will remain the inc only if we are not on a 2, or 3 boundary.
            else
               inc=1
            endif
         elseif(indi(n).eq.iused(n)-1)then
c On upper boundary face
            dx=xn(ixnp(n)+1+indi(n))-xn(ixnp(n)+indi(n))
            ipd=ipd-iLs(n)
cc On upper ipd is the point adjacent in the -(n) direction.
            fac=fac+x*dx
            inc=1
         endif
      enddo
cc When we reach here, we have ipd equal to an index to the point
cc adjacent in each of the dimensions, positive or negative according
cc as that direction was lower or upper face, zero if neither.
cc This is the point from which we are going to extrapolate. 
cc We have fac equal to x.dx where dx is the delta-x to position ipd.
cc And r2 is r^2. fac is r.dr 
      if(ipd.eq.ipoint)then
         write(*,*)'BDY function error; we should not be here'
         stop
      else
         fac=fac/(2.*r2)
cc scale fac by r^2
         u(ipoint+1)=u(ipd+1) *(1.-fac+D*fac)/(1.-fac-D*fac)
cc The boundary point is equal to the adjacent times 
cc (1-f+D*f)/(1-f-D*f). Multiplying this out gives:
cc U_p(1-f-Df) = U_d(1-f+Df). I.e. (U_p-U_d)(1-f)=(U_p+U_d)Df
cc The radius to the half-way point is rh2=(x-dx)^2 = r^2-2x.dx=r2(1-f)
cc So rh2*(U_p-U_d)/rh2.dr = D(U_p+U_d)/2 
      endif
c^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

So that more or less makes sense. I want to use the same sort of
algorithm if possible. I can use exactly this algorithm to determine
the point from which we extrapolate. Then when we find a non-zero dx
for a particular direction, if it is in the z-direction we need to 
use the M scaling. The criterion we need to satisfy is: 
  du/dr + M du/dz =0
So we can use the x,y difference to estimate the extrapolated value
as: u_p = u_d + (dx.r + dy.r)/r (du/dr) + dz (du/dz) 
with du/dr = -M du/dz. 
So u_p=u_d + (-M*(dx.x + dy.y)/r + dz).(du/dz)
If the du/dz is measured at u_d we can do it centered.
On the z-ends, dx=dy=0. This is then an identity and we can't do it
centered, but if we do it uncentered, it puts d^2u/dz^2 = 0. 
Why can't we do that for everything? Might be better. Sounds
unstable. 

We must do the substitution for du/dz at the z-ends instead.
   u_p=u_d + (-1/M)(du/dr)dz and du/dr estimated from mesh.
This looks as if it might get problematic at low M. 

Things don't look very implicit and I am not convinced that I've got
the right sort of approach. To do it right we need at least one
tangential and one normal step at each point. And the tangential step
must be in the z-direction unless we are on the z-face. If we are on
the z-face, we could use two tangential steps. A simpler fall-back
would be to make du/dz=0 on the z-faces.

Implemented that: mach on x,y-faces, zero-slope on z-faces.

It's pretty hard to test on the big domains.  Perhaps I ought to do
something on a smaller domain.  It is not obviously broken, but small
numbers of steps give a potential that is rather offset.
Anyway it is now easy to swap between the old and the new boundary 
conditions. 

Removed randc.o from the objects.

Ran for 650 steps after a restart. Still seemed to have a rather
negative average potential. 

Doing tests on a small 5x5 domain. The direction of contours is about
right. So it seems the boundary condition is doing its job. However,
there are cases where the potential is very depressed, so it seems 
as if that's an issue that needs to be resolved. Actually this effect
exists even with the old BCs. It gets really bad at 500 steps for
-v.5 and the small domain. This is not unique to the new version. The
problem's been there for a long time. Probably I need to fix it. 
I see that there's a big particle pump-out from a starting number of
90k down to about 30k. That's a symptom. How is rhoinfinity being
calculated? is the question. This is badly broken. Setting constant
number of particles does not fix it.

First it seems the sign of slpD was incorrect. But still that's not
the main problem. Seems to be worst at low temperature. Bad also with
zero velocity. Problem seems absent at -t1. This must be a bug with 
rhoinfinity calculation associated with temperature. At -t.1 -l1. it
asymptotes to -.13Te. At -t.01 to -1.75Te.

Seems as if the problem arises from phirein, which is exceeding its
capped value because of the low temperature. This corresponds to a 
value of chi equal to 0.5. But no, just setting chi to zero does not
fix it. 

I think there's a major problem with the way that rhoinf is being 
calculated from flux. If phirein is substantially bigger than Ti, 
which it is for pretty much all small domains when Ti is small, then
we are going to get very big swings in cfactor. This is going to be
unstable, probably. But the whole approach is highly dubious, for
a rectangular domain anyway. If the presheath drop to the edge of 
the boundary is significant, then we don't really have a decent
way of determining the rhoinf from the flux, because we don't have
a decent way (for a rectangular domain) of calculating how much flux
is going to enter. The cfactor is mostly just a kludge. If I turn off 
the chi/cfactor, then we just get the maxwellian flux calculated
across the boundary. But in reality there is a faster flux to the 
object than that. This means that at constant density there are many
more injections, which the rhoinf calculation takes as a sign that the
rhoinf is actually much higher than reality. But the electron density 
can't really be that high, because if it were, the whole box would be 
very negatively charged. So the potential everywhere in the box has 
a tendency to drop so as to reduce the electron density.

The flux at zero drift velocity is area x sqrt(2T_i/\pi). This seems
like a factor of 2 too much because it is for both faces.

The low potentials are mostly a sign that the rhoinf is being taken
too large. 

31 May 2010

Fundamentally, there has to be a way to allow the phirein to adjust
the rhoinf. The instability I have been observing is a problem but
just putting it against a rail is not the solution. 

Tried putting a relaxation parameter. It needs to be very small
to bring any degree of stability. Also, It seems that phirein
is quite often exactly zero. This is because phirein is capped in
padvnc never to be above 0. Also the energy of the injection is 
adjusted using averein, which is set to the prior value of phirein at
the start of a step. However, energy is never reduced, only enhanced.

Set the phirein cap to 2.Ti instead of zero. This works ok. It lowers
the edge potential a little, but it still tends on average to be
slightly above zero. It bounces around somewhat, which seems to be 
mostly statistics.

So what we have implemented is that the correction factor for edge
potential is relaxed by only by Ti/(1.+Ti). This is small at small
edge temperature and never goes above 1/2. These values appear to be
stable (experimentally). Also we have raised the phirein cap to 2Ti,
which helps prevent excessively positive edge potentials by allowing
the positive excursions to push down the chi value somewhat. 

We still find that the corners often rise above zero potential, but
this is probably caused by the incorrect boundary
conditions. Generally seems to work for a range of temperatures and
drift velocities.

Commit.

2 June

Had discovered that the wake has a problem in this new configuration.
There appear to be long wavelength waves along the box. This seems likely
to be caused by the release of the BC constraint. Since this case is 
poorly represented by the OML enhancement factor, one really ought not
to rely on that with such a big and asymmetric box. So make the 
leading face have zero potential. This ought to stabilize things.
This was a small modification to the bdymach routine. 

There's an issue about self force. I probably ought to make sure that
I avoid it. This is so only if the electric field interpolation and the 
charge assignment are done "consistently". It is not clear that I am
doing this. In principle either the charge or the field interpolation could
be adjusted to make things consistent. 

4 June Self Force.
Adjusting the charge assignment to zero the self force. 
This can be done. It is probably best done by assigning some of the charge
in a cell that is narrower than its neighbor to the adjacent cell further
away from the wider neighbour. (But not subtracting charge on the wide 
side). This can be considered to minimize the size of the charge. 

When the charge is at the half-step position, which is where the field
is defined, and can be considered the cell-boundary, the charge is
always shared equally between the two adjacent cells. When the charge
is exactly at the node position x_0, between nodes x_m and x_p, which
are distant from it by m, p, with m < p, the fractional charges are
q_p=0, q_0=0.5(1+m/p), q_m=0.5(1-m/p). Charge assignment varies
linearly between these values in the intermediate positions.

For uniform spacing this is exactly CIC. For non-uniform, it can be
considered to be an assignment by volume, of a rectangular charge
shape whose width changes in an area-conserving manner. When it is in
cell 0, its width is equal to the larger of m or p. And the area which
extends beyond the distances x_m/2 and x_p/2 (i.e. past this cell
boundary) are allocated to the adjacent nodes (not to non-adjacent nodes
even if the width extends far enough). 

Another way to think of it is that the particle weight at the nodes,
considered on a uniform mesh-fraction grid, when at a node that has
different step sizes on either side, takes an extended form. The
form morphs linearly in step-fraction from that form to the form of the
adjacent node, when the particle is at an intermediate point. The form
is S(x) m: 0.5(1-m/p), 0: 0.5(1+m/p), p: 0 (and linearly in between those). 
The linear interpolation distance is half a cell step (I think). 
Haven't got a good handle on this description. 

17 June 10
Found that the oscillations that I got stuck with were caused by using
fixed particle number -ni, instead of fixed injection rate -ri. 

30 June 10

Also found that even using fixed injection rate at lower M=0.5 there
are oscillations. The plan is therefore to implement a switch that
totally simplifies the BCs so that reinjection is at a specified rate
calculated as the rate corresponding to distant fluxes regardless of
potential, and the potential boundary condition is simply on the
gradients, possibly using the diagonal expression. This ought to be
sufficient to give a stable scheme. It might lead to some slight edge
screening effects, but that ought not to be a problem. 

Try to sort out the reinjection number logic and the way they are
controlled for the following parameters:

rhoinf the density at infinity summed over processors.
calculated in rhoinfcalc each iteration
if nrein!=0, rhoinf=nrein/(dtin*cfactor*flux), else guess from n_part.
cfactor is the adjustment for non-zero edge potential. 

nrein
the actual number of reinjections in the step summed over all processors.

ninjcomp refers during iterations to one processor's complement.
At initialization, if rhoinf !=0, set in nreincalc.

n_part one processor's number of particles. Set by -ninnn switch. 
If n_part!=0 during initialization, then set rhoinf=0, so nreincalc is not 
called. 

-ri sets value of rhoinf __per node__, which then is converted into ninjcomp
by nreincalc, at which time, rhoinf is multiplied by nproc to make it total.

-ni sets n_part.

To reduce confusion, rename nreincalc to ninjcalc. ninjcomp is the most 
important thing set by ninjcalc. Also introduce new initial variable
ripernode which is what rhoinf was prior to being multiplied by 
numprocs. In other words we no longer overload rhoinf during the initalization.

Introduce new switch -rx determining the relaxation rate of chi, the
edge potential correction (and of averein). Default 1 immediate.
Set to zero there is no edge potential correction of the flux or of the
injection energy.

Corrected dtprec to store for each particle, as per sceptic. This is
the only way to get subcycling etc to work properly. Also set it to
zero in the pinit, do not set it to dt at the start of padvnc. This
latter change makes a big difference to the value after 5 steps. Amounts
to supposing that the particle load occurs with perfect reinjection 
form of distribution function. 
Need then to set dtprec(i)=dtpos at the standard end of each cycle.
That restores much of the difference in flux. 

Working on subcycling. If we calculate the square of the field, f2. 
then perhaps we can determine automatically whether the step is 
small enough. A criterion might be field*dt (= delta v) > some typical
velocity. The parameter subcycle could perhaps be used to set the
criterion, e.g. sqrt(f2)*dt > subcycle (normalized). Another way to
say the same thing is that dt should be shortened until f.dt < subcycle.
An integer subcycle criterion would then be
   dtc = dt/max(1, int(f*dt/subcycle))

This seems to work. Arrange to print out the number of particles subcycled,
if non-zero. 

13 July 2010

Tried out v.5 -rx0. case on 8-processor machine. Its oscillations are
substantially reduced c.f. the previous problems, but not gone away.

Found a bug in fluxdata reading and writing. This is because we need
the address of the next (unused) ff_data slot, to determine how much
ff_data to read/write. I had hacked it to omit the last. Now I need to
make it right. Trouble is with old data flux data files. Do I want to
be able to read them? I think it's not worth it. Assume for now that I don't. 
But put comments in about how to recover the old data files.

15 July 2010

The -rx0 without holding the leading edge potential fixed has rather low
edge oscillation problems and seems to run reasonably convincingly. 

However even at -p0.2 we have not apparently reached a linear regime.

Set going the -v0.8 cases.

Some code clean-up, especially of the main program. 

31 July 2010

In view of the discrepancies with Lampe's plot of the wake, I am
considering a way to represent a point charge as a pseudo-object of
zero extent. It could be added to the object file as a new type.

There seem to be two ways to implement this. 

1. Simply put extra point charge(s) of specified magnitude greater
than unity into the region at arbitrary position in the grid, and
place the charge onto the grid via the standard chargetomesh process.
This is essentially trivial, but it suffers from accuracy challenges
close to the charge. In effect, accurate field representation in the
vicinity of the charge will be limited to the size of the mesh there. 

2. Put into the field a coulomb representation of the point charge(s).
This has the benefit of NOT requiring fine mesh to represent the point
charge influence. However, we need to solve the rest of the shielding
problem properly. It becomes a sort of PPPM approach. If we add to the
field the force of the coulomb field, and solve the Poisson equation
for the residual potential (with the coulomb potential removed), then
we will have a good solution provided we resolve the shielding. This
will permit us to do without a fine scale near the charge, and resolve
only the shielding (Debye) scale length. This would be a serious benefit.
(There will be some display issues in that we will want to add back the
coulomb parts of the potential for display purposes.) 

Since we solve the electron shielded Poisson problem, 

      \nabla^2 \phi + \phi/\lambda^2 = \rho  ,

we need to account for the coulomb field in that solution. We will be
tracking only   u  =  \phi - \phi_c  where \phi_c is the coulomb part
of the potential. Consequently the correct equation for u is

      \nabla^2 u + u/\lambda^2 = \rho + \phi_c/\lambda^2  ,

Thus we simply need to add \phi_c/\lambda^2 to the charge. This could
perhaps be done in psumtoq.

It might therefore be convenient to store \phi_c for use both in obtaining
q and in plotting the total \phi = u + \phi_c. It is fixed (but the charge
could perhaps be permitted to change in time). In any case it ought to be
in a separate common block that contains the information about the additional
charges. (There might be a cache inefficiency in it being far from u).

There will then be an issue with boundary conditions on u. The
boundary values of \phi_c will have to be subtracted from the BCs for
\phi.  This looks like the tricky part. For example bdymach would have
to have access to \phi_c. Since it will have the same structure as u,
it ought not to be too problematic to access its elements appropriately.
Looking through bdyroutine.f for u(, it does not look too difficult
to change those all to be u+\phi_c. In the long run it might be a bit
cumbersome to do this, but probably not more confusing than the logic
of those iteration routines anyway. 

The problem with the above is that it is only true for the linearized
approximation to the Boltzmann factor. Really we have to solve

      \lambda^2 \nabla^2 \phi = n - \exp{\phi}  ,

and the non-linearity of the additional operator prevents us exactly
translating from u to phi by the addition of constant u_c into the
equation.  It has to be in the exponent. Part of this awkwardness
arises from the fact that faddu is written so that it just takes the
exponential of its argument. Because the index of the u array is not
passed, it is not possible for the function to correct for a phi_c
offset. It seems that it ought to be unproblematic to have additional
arguments for faddu such as the array index. Faddu is called only in
sorrelaxgen. One could at the index as the last argument without 
breaking the current call (I think).